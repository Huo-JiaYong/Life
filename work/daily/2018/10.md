### 10 - 8

1. 修复消息堆积导致的节点重复问题
2. 完善处理流程中的日志信息

### 10 - 9

1. es 导入 json 文件

   ```shell
   curl -H "Content-Type: application/x-ndjson;" -s -XPOST localhost:9200/accounts/usa/_bulk --data-binary @accounts.json
   ```

2. es 的精确搜索、全文搜索、短语匹配、字段排序、高亮搜索

   1. match : {"field" : "value"}

      range : {"field":{"gte":20, "lte":30}}

      sort : {"field" : "desc"} 

   2. match : {"field": "value value"}  , 根据字段与值的匹配度进行**相关性评分**，分最大的在前面

   3. match_phrase : {"field":"value1 value2"} 根据短语 `value1 value2` 进行匹配

   4. highlight : {"fields":{"field":""}} 高亮显示 `field` 字段的匹配内容，具体高亮的词由分词器决定

3. es 的聚合函数基础使用

   1. data  - employee:{"properties":{"interests":{"type":"text",fielddata:true}}} 设置 interests 字段为 text 并且**支持聚合**
   2. aggs:{"AGGS_NAME":{"AGGS_TYPE":{"field":"interests"}}} 聚合函数的使用

### 10 - 10 

1. es 创建集群需要指定 cluster.name (default: elasticsearch)

   集群的扩展：横向扩展（加数量），纵向扩展（加性能）。横向扩展更具性价比和实用性，也是分布式的主要理念

2. Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里

3. 创建 index 会使用默认的分片数:5

   创建： PUT megacorp {"settting":{"number_of_shards":3,"number_of_replicas":1}}

   分片数：3  每个分片数的副本数：1

   修改： PUT megacorp/_settings {"number_of_replicas":1}

4. 节点掉线后重新上线，只需要复制修改的数据到刚刚掉线的节点上

5. _index/\_type/\_id  即可确定一个文档的具体位置， _type 新版本中被移除

6. GET _source 能只获取文档的内容，而不获取文档的其他信息（ _version 等）

7. es 异步就可能导致数据的错误

   1. 内部版本号：在每次更新数据时，自带的版本号会自动新增

      在更新时可以指定 ?version=xx 来更新指定版本，若真实版本号大于此版本号值则更新失败

   2. 外部版本号：版本号由用户自己维护（> 0 && < 9.2E+18 的整数）

      创建时： ?version=20181010180000&version_type=external

      更新时： ?version=20181010180001

8. 指定操作类型  _create  _update

9. 使用脚本更新文档内容

   POST accounts/usa/1/\_update {"script":"ctx.\_source.age += 10"}

### 10 - 11

1. 新增定时清理已扫描完成的功能
2. 新增扫描任务长时间未返回扫描结果的情况下重新发布此文件的扫描任务
3. 新增最近10个任务的文件缓存。避免多个请求同时获取一个文件，导致文件被读取多次（占用过多内存）

### 10 - 12

1. 修改最近扫描任务的缓存方式

2. 请求多个文档

   GET _mget {"docs":[{"\_index":"accounts","\_type":"usa","\_index":1}]}

   GET accounts/usa/_mget {"ids":[1,2]}

3. 批量修改

### /

### 10 - 15

1. 这暗示 *数组中所有的值必须是相同数据类型的*, 会用数组中第一个值的数据类型作为这个域的类型

2. 使用分析器对数据进行拆分测试

   GET _analysis {"analyzer":"standard", "text":"china is a good country"}

3. 自定义文档的类型和分词器

   ```json
   // PUT accounts
   {
       "mappings":
       	"uk":
               "properties":{
                   "firstname":{
                       "type":"string",
                       "analyzer":"english"
                   },
                   "age":{
                       "type":"long"    
                   }
   		}
   }
   ```

### 10 - 16

1. 处理南京服务器遇见的问题
   1. 扫描节点显示在线，却没有扫描文件（实际就是节点不在线）
   2. 扫描时间显示错误，尝试修改服务器时区及时间都无效。发现数据库时间正确，获取后不正确。确定为序列化错误。在配置文件中新增 jackson.time-zone=GMT+8
   3. 清理南京服务器的历史数据和临时文件

### 10 - 17

1. 参加trac培训

2. 高频度访问redis，导致任务清理线程死掉。进而导致任务堆积不能被扫描

   1. 从清理掉 scan.task.list.cleaning 标记能重新发布任务的情况下就应该发现线程死掉的问题

      但是总是觉得自己是对的，这个问题出的莫名其妙。是机器捉弄我胖虎。

      首先态度是不对的，要怀着怀疑的态度去看程序.定位到问题就要想去怎么解决，而不是心里推脱

      其次没有严格的检查程序（其实就是对线程不了解），排查的时候不仔细。没有覆盖到所有代码，只是在这个方法里看（关键在于自己排查不仔细，没有进入到方法里）

   2. 在进行测试的时候，并没有对超大量任务进行测试。测试只是点到为止，但是测试的目的就应该是多模拟多种情况的。只有多测试才能保证项目能更少的BUG，而不是用通过测试来**麻痹自己**。

### 10 - 18

1. 修改在线引擎的记录、更新方式，避免出现高并发下获取在线引擎失败的情况
2. 修改获取在线引擎数量错误的问题

### 10 - 19

1. 定位很多文件上传后出现的扫描时间依次递增的问题
2. 自查代码确定问题在于多线程访问同一资源导致的锁等待，导致新增扫描结果时间过长

### / 

### 10 - 22

1. 广东服务器mysql启动错误处理，并清理相关数据

2. 解决高并发下任务堆积导致任务扫描时间递增的问题

   **注意同步块的使用，多个同步块则可能导致多线程的效率指数级的下降**

3. 修改任务的扫描结果列表的存放方式

4. 修改扫描数量的统计为任务扫描完成后统计

### 10 - 23

1. 修改下载文件流程，避免同一文件在同一节点中多次下载

   **为什么从一开始就不能设计、商量好再做，想的太少。脑子里都是空白的**

2. 学习 CICD 的使用方式和 jenkinsfile 创建

### 10 - 24

1. 重构待扫描文件的任务队列处理流程和优先级队列的管理

### 10 - 25

1. 上午学习 CICD 操作流程和配置文件规范化
2. 优化任务队列发布处理逻辑并测试效率
3. 优化任务的发布方式，避免频繁创建、销毁线程

### 10 - 26

1. 新增长时间未扫描任务的重发机制

   超过指定时间的任务未扫描完成，则重新发布此文件未返回结果结果的引擎扫描任务

2. 修改无任务的引擎列表的处理机制

3. 修改所有信息的缓存方式，进一步去redis化

### /

### 10 - 29

1. 所有统计信息去redis化，将统计信息存放到数据库中
2. 修改扫描数据同步频率，避免多线程修改统计扫描文件计数导致数据错误

### 10 - 30

1. 修改 OAuth 认证的存放机制和账户管理等相关处理逻辑
2. 测试在 docker 环境下的修改的功能正确性

### 10 - 31

1. 修复首页获取在线引擎数量的节点信息错误的情况

2. 准备给北京演示的程序和环境

3. 修复多节点中出现的任务队列错误情况

   直接返回/修改静态对象，导致返回的地址的数据会被修改。进而导致数据错误

