## 多线程

#### 线程状态

1. start \ run \ sleep（计时等待） \ wait （等待）\ yield（让行） \ join（等待其他执行）
2. sleep 和 wait 的区别
   1. wait 属于 object 类中的方法，需要获得对象的锁
   2. wait 需要在同步代码块中
   3. wait 会释放锁，sleep 不会
   4. sleep 延迟状态自动结束，wait 需要被唤醒

#### 线程池

1. Fixed 、Single、Scheduled、Cache
2. 任务的顺序：coreSize > queueSize > maxSize 
3. 拒绝策略：直接拒绝、调用者运行、丢弃最老、直接丢弃
4. Fixed、Single 默认队列大小为 Integer.MAX ，可能 OOM
5. Scheduled、Cache 默认线程池大小为 Integer.MAX，可能 OOM
6. 线程池推荐大小：CPU密集 n+1 、IO密集 2n

#### 线程安全

读多写少的情况下，推荐使用乐观锁（尽量减少加锁的行为）：Version \ Compara And Swap

##### synchronized

synchronized 修饰代码块（monitorenter monitorexit）和方法 （flags）

1. 实现：对象头中 Mark word 记录对象hash、锁信息（持有线程id 、锁状态等）、年龄分代、GC标志等
2. 锁状态：无锁、偏向锁（当前线程优先）、轻量锁（CAS避免切换线程）、重量锁（阻塞其他线程）

##### Lock

1. ReentrantLock 官方提供的互斥锁，锁实现采用自旋，不断循环调用CAS操作来避免线程进入内核阻塞状态
2. 公平锁的实现方式：所有的线程请求锁时，都将放入一个队列中。按照 FIFO 的方式获取锁
3. 公平锁因为要放入队列然后在获取，当只有一个线程时，也会执行此操作。涉及到切换，所以效率低

##### synchronized & ReentrantLock 

1. sync 是 JAVA 关键字，R 只是提供的一个 API
2. 原理：锁状态的升级，R 使用CAS自旋机制实现操作原子性 和 volatile 实现可见性
3. 使用：sync 自动释放，R 需要手动释放锁
4. sync 不可中断，R 可以使用超时方法、调用 interrupt 方法
5. sync 不可设置公平锁，R 可以设置

##### AQS 思想

抽象式的队列同步器，是一个用来构建锁和同步器的框架。

同步器：用以实现原子化操作的一种方案

队列：线程阻塞和唤醒时分配方案

常见实现：Lock 、CountDownLatch（计数）、Semaphore（信号量）

##### ThreadLocal

1. ThreadLocal 是指定的对象会被保存到 Thread.threadLocalMap 中
2. ThreadLocal 内存泄露的问题：Map 中 key 是对象的弱引用，可能被回收了。value 是强引用没有被回收

##### 锁优化

1. 如何优化锁的使用：
   1. 减少锁应用的范围
   2. 减小锁力度（拆分多个锁）
   3. 锁粗化（避免多次操作）例：在循环外加锁
   4. 根据场景选择不同的锁
   5. 使用 CAS 乐观锁 + volatile

#### 内存模型

1. 线程安全主要就是保护内存数据（资源）的一致性

   原子性 - sync

   可见性 - volatile \ final

   有序性

2. volatile 使用 lock 指令实现内存可见性 + 有序性，建立内存屏障并禁止指令重排
   1. 强制写入到主内存
   2. 写入会导致其他 core 缓存失效
   3. 禁止之后的指令重排到之后 lock 之前

## Spring

#### 主要功能

1. IoC（Inverse of Controller）将对象的管理权限交给框架管理，IoC 容器实际上是 Map
2. DI（Dependancy Injection）使用容器将对象引入
3. AOP（Aspect-Oriented Programming）面向切面编程，降低系统模块耦合度

#### Bean

##### 生命周期

singleton：和 IoC 容器一个周期

prototype：使用时创建，使用过程中一直存活，不用被 GC 回收

大致四个阶段：

1. 实例化（instantiation）
2. 属性赋值（populate）
3. 初始化（initialization）
4. 销毁（destruction）

##### 加载流程

1. 实例化（new Object）
2. 设置属性（设置各个属性值，注入依赖的 bean 等）
3. Aware（BeanNameAware、BeanFactoryAware、ApplicationContextAware）
4. BeanPostProcess 的 postProcessBeforeInitialization() 
5. 调用指定 init-method 方法
6. postProcessAfterInitialization()
7. 创建完成，可以使用

##### 清理 Bean

1. 实现的 DisposableBean 接口
2. 调用指定 destory-method 方法

##### 循环依赖

Spring 采用三级缓存的方式来解决循环依赖的问题

一级缓存（singletonObjects）：创建好的所有 singleton Bean

二级缓存（earlySingletonObjects）：在调用 getSingleton() 从三级缓存中移出的对象

三级缓存（singletonFactories）：刚实例化的 Bean **包装到 ObjectFactory 中**

![循环依赖的返回](img/spring三级缓存.png)

##### 为什么是三级缓存

一级：已设置完整属性的对象

三级：所有刚实例化的对象

为什么一三级要分开：区分不同属性状态的对象

二级：区分代理对象和 ObjectFactory 对象

1. 调用三级缓存的 ObjectFactory.getObject()  返回的为一个 BeanProxy 对象
2. 如果当前对象被 AOP 进行切面代理，每次都将返回一个新的对象 （不符合单例）
3. 所以将产生的 BeanProxy 对象放入到二级缓存中，下次直接获取即可

##### IoC 容器的启动流程

```java
public AnnotationConfigApplicationContext(Class<?>... componentClasses){
    // 1.加载 RootBeanDefinition 2.解析配置类 3.解析@Import和@Bean
    this();
    
    // 注册配置类
    register(componentClasses);
    
    // 下面的加载 bean 流程
    refresh();
}
```

##### IoC 容器加载 bean 流程

1. prepareRefresh() **刷新预处理**
2. obitionBeanFactory() 销毁 old BeanFactory **创建新 BeanFacotry** 并注册到 BeanDefitionRegistry
3. prepareBeanFactory() **预处理**，加载 Context 的 ClassLoader
4. /
5. postProcessBeanFactory() **前置处理**
6. invokeBeanFactoryPostProcessors()  **实例化 BeanFactroyPostProcess** 的 bean
7. registerBeanPostProcessors() **注册 BeanPostProcess 的后置处理**
8. /
9. initMessageResource() **初始化国际功能**
10. initApplicationEventMulticaster() **注册事件派发器**
11. onRefresh() **容器刷新**
12. /
13. registerListeners() **注册监听**
14. finishBeanFactoryInitialization() **初始化所有非懒加载的单例 Bean**
15. finishRefresh() **Context 刷新**

##### 事务的传播机制

1. REQUIRED	有事务则加入，没有则创建
2. SUPPORTS	有事务则加入，没有则非事务运行
3. MANDATORY	有事务则加入，没有抛异常
4. REQUIRES_NEW	有事务则挂起，用重新创建
5. NOT_SUPPORTED	有事务则挂起，用非事务运行
6. NEVER	有事务则抛异常，用非事务运行
7. NESTED	局部回滚

##### 事务失效的场景

1. 使用非代理的方式运行
2. 方法非 public 
3. 数据库不支持

## MySQL

#### 数据库事务的四特性 ACID

1. 原子性（Actomicity）：多个操作只有一个最终结果
2. 一致性（Consistent）：多个事务读取同一数据应该是一样的
3. 隔离性（Isolation）：多个事务之间不应该相互干扰
4. 持久性（Durable）：事务的结果应该被永久的保存

InnoDB： `回滚日志(undo)`保证原子性 `重做日志(redo)`保证一致性和持久性 `锁`保证隔离性



#### 数据错误术语

1. 脏读：读取未提交的数据，后未提交的数据被回滚
2. 不可重复读：多次读取的结果不一致
3. 幻读：出现新的数据，数据条数不一致



#### 事务的隔离级别

读未提交（Read Uncommitted）：允许读取未提交的事务数据  ——幻读、脏读、不可重复读

读已提交（Read Commit）：允许读取已提交的事务数据  ——幻读、不可重复读

可重复读（Repeatable Read）：多个事务读取同一数据是一致的  ——幻读

顺序读（Serializable）：所有事务依次读取

##### 默认等级（Repeatable Read）

解决幻读的方案：

1. 采用 Serializable 级别，所有事务按照顺序执行（效率低）
3. 采用 Gap Lock + Next-Key Lock 方案，对一个范围进行加锁
3. 采用 MVCC （Mulite-Version Concurrency Control）方案，指定版本就可以确定是否为最新的数据



#### 锁级别

##### 表级锁：（Serializable ）

1. 意向锁（Intention Lock）：MyISAM 和 InnoDB 都支持
2. MDL 锁：对表结构做修改时的锁
3. AUTO-INC 锁：自增时的锁，插入后自动释放

**显式使用：（默认会自动加）**

1. LOCK TABLES xx READ （可选 LOCAL：可以在表尾插入）
2. LOCK TABLES xx WRITE
3. （解锁）UNLOCK TALBES

##### 行级锁：（RC 和 RR）

1. 记录锁（Record Lock）：对某一行的 **索引项** 进行加锁，有锁才能修改和删除
2. 间隙锁（Gap Lock）：对指定行的 **前后索引区间** 进行加锁，其他事务不能在锁的区间内插入数据
   1. 唯一索引：锁住多条记录 OR 不存在的记录 会产生间隙锁
   2. 普通索引：不管什么都会产生间隙锁
3. 临键锁（Next-Key Lock）：对 **某一行的索引项 和 前后索引区间** 都加锁（记录锁+间隙锁），可解决幻读问题

**显式使用：**

使用 select ... IN LOCK SHARD MODE（行级读锁）

使用 select ... FOR UPDATE（行级写锁）



#### 锁类型

##### 读写锁

1. 共享锁（Shared Lock，S）：允许持有锁 **读取行** 的事务，也叫读锁
2. 排他锁（Exclusive Lock，X）：允许持有锁 **修改行** 的事务，也叫写锁

**注意：普通的 select 是不会加行锁的，而是使用 MVCC 实现一致性，是无锁的**

在表级和行级都有读写锁

表级：MySQL 定义 

行级：InnoDB 提供

##### 意向锁

在 InnoDB 中支持多粒度锁，允许 表级锁 & 行级锁 共存。**意向锁是一个表级锁**

因为行和表都有锁，那么需要考虑如何让这两种锁共存 ？就有了

参考：https://www.51cto.com/article/743293.html

1. 意向共享锁（Intention Shared Lock，IS）：有意向对 **某些行** 加共享锁（读），InnoDB 会自动先获取**表的意向读锁**
2. 意向排他锁（Intention Exclusive Lock，IX）：有意向对 **某项行** 加排他锁（写），InnoDB 会自动获取**表的意向写锁**

作用：

1. 当在使用行级锁时，引擎会自动添加表级意向锁（意向锁不互斥：多行锁可以同时）
2. 当其他事务在需要获取表级锁（互斥的情况）的时候，则只需要判定是否存在意向锁即可
3. **避免了互斥的情况下，需要去判定每行是否存在排他锁的问题**

互斥：

1. 意向锁之间都不互斥
2. 只有共享锁之间兼容，其他都互斥



#### MVCC

InnoDB 在每行数据后面保存**系统的版本号**，**每开始一个新事务都会自动递增**，并作为事务的 ID（确保事务读取的行已存在，避免幻读）

InnoDB 中 MVCC 使用到的快照存储在 undo 日志中，该日志通过**回滚指针**把一个数据行的所有快照连接起来

版本链，在聚簇索引记录中的两个隐藏列：

1. trx_id：事务 id
2. roll_pointer：每次修改时都会把老版本写入到 undo 日志中，这个指针就指向这条聚簇索引的上一版本的位置



#### 索引

##### 数据类型

1. HASH 索引：使用数据的 hash 值作为索引项，数据和索引项一对一（不能进行范围搜索，排序等）
2. B+ 树索引：非叶子节点存储索引，放入缓存提升效率；叶子节点存储数据，做双向链表进行范围查询

##### 索引类型

1. 聚簇（集）索引：保存索引 和 数据（不用再次查询）

   1. 主键索引 = 聚簇索引  = 覆盖索引，**一定会有主键索引，一定是聚簇索引。没有则使用其他唯一索引，没有则使用隐藏 id**

2. 非聚簇（集）索引：保存索引 和 主键值（通过主键值再次查询——回表）

   1. 唯一索引 （UNIQUE）

   2. 联合索引：需要注意 **最左前缀匹配** 问题

      联合索引的索引键是以最左的字段来确定的，所以查询时未指定最左字段则无法使用索引

   3. 全文索引（FULLTEXT）



##### 查询执行

1. 接收到 select 语句后，在 query cache 中匹配是否有相同的语句（大小写），有则直接返回

2. 将 select 语句交给解析器进行语法解析，生成解析树

3. 查询优化器生成执行计划，进行索引优化

4. 引擎执行 SQL 语句，得到查询结果。执行顺序

   form > join > on > where > group by > avg,sum... > having >select > distinct >order by > limit

5. 开启 Query Cache 则放入，后返回结果



##### 查询优化

1. explain 关键值： type（是否全表扫描）、rows（预估的行数）、 extra（详细的描述）

2. 语句优化：

   1. **查询条件使用索引**
   2. count 会全表扫描，预估可以使用 explain 方式
   3. 分页 start 值过大会缓慢，使用子查询 + 表连接解决
   4. 删除表会产生 undo 和 redo 日志，确定删除使用 trancate

3. 索引优化：

   1. 无法使用索引：><、!= 、IS NULL、OR、IN、NOT IN
   2. **使用短索引**
   3. 索引的区分度要高，唯一索引的重复率 < 0.1
   4. 定义外键的列一定要又索引
   5. 更新频繁的列不适合做索引
   6. 查询的数据较少可以通过联合索引来进行覆盖
   7. 联合索引要符合最左匹配原则

4. 设计优化：

   1. 表 < 200
   2. 列 < 40
   3. 行 < 500w
   4. 单表索引 < 5

5. 配置优化：

   **配置连接数**、禁用 Swap、增加内存、升级 SSD



##### JOIN 查询

![](https://www.runoob.com/wp-content/uploads/2019/01/sql-join.png)

#### 集群

##### 数据一致性问题

1. 异步复制：主库写入成功后直接返回，可能主从数据不一致
2. 半同步复制：等从库同步到 relay-log 后主库返回结果
3. 全同步复制：所有从库都执行成功后主库返回结果

##### 集群方案

1. **MySQL Replication**

   1. 从节点：开启 IO 线程，向主服务器请求同步 binlog 文件
   2. 主节点：开启 dump 线程，检查自己的 binlog 文件并发送给从节点
   3. 从节点：接受到 binlog 文件并保存到 Relay log 文件中
   4. 从节点：开启 SQL 线程，执行 Relay log 中的操作

   注：binlog 记录格式：STATEMENT | ROW | MIXED

2. MySQL Group Replication（MGR）：多个节点组成复制组，必须 n/2 + 1 的节点通过后才提交

3. **InnoDB Cluster**：高可用的解决方案

4. InnoDB CluseterSet：多个副本（不同区域）的 innodb cluster，提供容灾能力

5. InnoDB ReplicaSet：使用 MySQL Router 进行引导配置，非常适合扩展读取

6. Master-Master for MySQL（MMM）：支持双主的切换和管理的脚本，使用 prel 编写

7. **Master-High Avaliablity for MySQL（MHA）：**一款优秀的高可用环境下故障切换和主从提高的软件，可自动提升节点、切换主节点

8. Galera Cluster：多主集群，是一种高冗余架构

9. **MySQL Cluster：**支持 ACID 事务的实时数据库，基于分布式架构

##### MHA | QMHA 升级主节点步骤

1. 尝试修改 old-master 为 read_only = on，避免集群多点写入
2. 将 binlog server 保存 old-master 的 binlog 文件同步到  new-master 上
3. 在 new-master 使用 binlog 进行数据补齐，避免丢失数据

#### 分库分表

将一个表拆分成多个（降低数据量压力），再将多个表放入到多个库（降低并发压力）分散压力

##### 分库和集群

​	集群：将一个数据库复制到多个机器（多个机器被视为一个库）

​	分库：将数据分布到多个机器（多个库）

##### ShardingSphere

1. 引入 sharding-jdbc-spring-boot-starter 包

2. 指定配置：

   ```yaml
   spring:
   	shardingsphere:
   		# 1.配置多个库信息
   		datasource:
   			names: d1, d2
   			d1:
   				type: com.zaxxr.hikari.HikariDataSource
   				driverClassName: com.mysql.cj.jdbc.Driver
   				jdbcUrl: jdbc:mysql://localhost:3306/sharding_db
   				username:
   				password:
   		# 2. 配置分片信息
   		sharding:
   			tables:
   				order:
   					# 2.1 分在那些库、表内
   					actual-data-nodes: d$->{1..2}.t_order_$->{1..2}
   					# 2.2 主键生成策略
   					key-generator:
   						cloumn: id
   						type: SNOWFLAKE | UUID
   					# 2.3 分库策略
   					database-strategy:
   						inline:
   							sharding-cloumn: id
   							algorithm-expression: d$->{id%2+1}
   					# 2.4 分表策略
   					table-strategy:
   						inline:
   							sharding-cloumn: id
   							algorithm-expression: t_order_$->{id%2+1}
   ```

##### 分片策略

1. inline：指定某一个行确定分片

2. strandard：

   1. precise-algorithm-class-name：新增时的自定义分片策略
   2. range-algorithm-class-name：查询范围时确定应该去哪些分片执行的策略

3. complex：多个分片键确定分片

4. hint：和 SQL 不相关的条件去分片（直接自行确定应该在那些库和表）

   例：下单人是成都的，那我就直接指定他去成都库查就行了

##### 读写分离方案

1. 配置主库： sharding.master-slave-rules.{库别名}.master-data-source-name: d1
2. 配置从库： sharding.master-slave-rules.{库别名}.slave-data-source-names[0]: d2
3. 指定逻辑库：sharding.tables.{表别名}.actual-data-nodes: ${库别名}.t_name
4. **在  MySQL 中设置读写库同步**

##### 常见问题

###### 双写不中断迁移

1. 让新库加入到所有的读写操作中
2. 通过新库的起始 id 就可判断之前的是旧数据
3. 通过程序将旧库中的数据写入到新库中，写的时候判断 updateTime
4. 循环执行，直至新老一致，则可关闭旧库

###### 分布式自增唯一主键

1. 可用 redis 的方式 （10W级）
2. 雪花算法
3. 自定义主键生成策略

###### 富查询

多维度实时查询最常见的方式是：将查询的字段放到 ElasticSearch 中，那后续扩展加字段呢 ？

###### 深分页

1. 按游标进行查询 offset ?
2. 查询带上上一次查询排序后的最大 id（不能跳页）

###### 数据倾斜

分表 & 取余