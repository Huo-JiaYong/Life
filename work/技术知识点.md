## 集合



## 多线程

### 线程状态

1. start \ run \ sleep（计时等待） \ wait （等待）\ yield（让行） \ join（等待其他执行）
2. sleep 和 wait 的区别
   1. wait 属于 object 类中的方法，需要获得对象的锁
   2. wait 需要在同步代码中
   3. wait 会释放锁，sleep 不会
   4. sleep 延迟状态自动结束，wait 需要被唤醒

### 线程池

1. Fixed 、Single、Scheduled、Cache
2. 任务的顺序：coreSize > queueSize > maxSize 
3. 拒绝策略：直接拒绝、调用者运行、丢弃最老、直接丢弃
4. Fixed、Single 默认队列大小为 Integer.MAX ，可能 OOM
5. Scheduled、Cache 默认线程池大小为 Integer.MAX，可能 OOM
6. 线程池推荐大小：CPU密集 n+1 、IO密集 2n



### 线程安全

读多写少的情况下，推荐使用乐观锁（尽量减少加锁的行为）：Version \ Compara And Swap

#### synchronized

synchronized 修饰代码块（monitorenter monitorexit）和方法 （flags）

1. 实现：对象头中 Mark word 记录对象hash、锁信息（持有线程id 、锁状态等）、年龄分代、GC标志等
2. 锁状态：无锁、偏向锁（当前线程优先）、轻量锁（CAS避免切换线程）、重量锁（阻塞其他线程）

#### Lock

1. ReentrantLock 官方提供的互斥锁，锁实现采用自旋，不断循环调用CAS操作来避免线程进入内核阻塞状态
2. 公平锁的实现方式：所有的线程请求锁时，都将放入一个队列中。按照 FIFO 的方式获取锁
3. 公平锁因为要放入队列然后在获取，当只有一个线程时，也会执行此操作。涉及到切换，所以效率低

#### synchronized & ReentrantLock 

1. sync 是 JAVA 关键字，R 只是提供的一个 API
2. 原理：锁状态的升级，R 使用CAS自旋机制实现操作原子性 和 volatile 实现可见性
3. 使用：sync 自动释放，R 需要手动释放锁
4. sync 不可中断，R 可以使用超时方法、调用 interrupt 方法
5. sync 不可设置公平锁，R 可以设置

#### AQS 思想

抽象式的队列同步器，是一个用来构建锁和同步器的框架。

同步器：用以实现原子化操作的一种方案

队列：线程阻塞和唤醒时分配方案

常见实现：Lock 、CountDownLatch（计数）、Semaphore（信号量）

#### ThreadLocal

1. ThreadLocal 是指定的对象会被保存到 Thread.threadLocalMap 中
2. ThreadLocal 内存泄露的问题：Map 中 key 是对象的弱引用，可能被回收了。value 是强引用没有被回收



#### 锁优化

1. 如何优化锁的使用：
   1. 减少锁应用的范围
   2. 减小锁力度（拆分多个锁）
   3. 锁粗化（避免多次操作）例：在循环外加锁
   4. 根据场景选择不同的锁
   5. 使用 CAS 乐观锁 + volatile

#### 内存模型

1. 线程安全主要就是保护内存数据（资源）的一致性

   原子性 - sync

   可见性 - volatile \ final

   有序性

2. volatile 使用 lock 指令实现内存可见性 + 有序性，建立内存屏障并禁止指令重排
   1. 强制写入到主内存
   2. 写入会导致其他 core 缓存失效
   3. 禁止之后的指令重排到之后 lock 之前
   
   

## Spring

### 主要功能

1. IoC（Inverse of Controller）将对象的管理权限交给框架管理，IoC 容器实际上是 Map
2. DI（Dependancy Injection）使用容器将对象引入
3. AOP（Aspect-Oriented Programming）面向切面编程，降低系统模块耦合度

### Bean

#### 生命周期

singleton：和 IoC 容器一个周期

prototype：使用时创建，使用过程中一直存活，不用被 GC 回收

大致四个阶段：

1. 实例化（instantiation）
2. 属性赋值（populate）
3. 初始化（initialization）
4. 销毁（destruction）

#### 加载流程

1. 实例化（new Object）
2. 设置属性（设置各个属性值，注入依赖的 bean 等）
3. Aware（BeanNameAware、BeanFactoryAware、ApplicationContextAware）
4. BeanPostProcess 的 postProcessBeforeInitialization() 
5. 调用指定 init-method 方法
6. postProcessAfterInitialization()
7. 创建完成，可以使用

#### 清理 Bean

1. 实现的 DisposableBean 接口
2. 调用指定 destory-method 方法

#### 循环依赖

Spring 采用三级缓存的方式来解决循环依赖的问题

一级缓存（singletonObjects）：创建好的所有 singleton Bean

二级缓存（earlySingletonObjects）：在调用 getSingleton() 从三级缓存中移出的对象

三级缓存（singletonFactories）：刚实例化的 Bean **包装到 ObjectFactory 中**

![循环依赖的返回](img/spring三级缓存.png)

#### 为什么是三级缓存

一级：已设置完整属性的对象

三级：所有刚实例化的对象

为什么一三级要分开：区分不同属性状态的对象

二级：区分代理对象和 ObjectFactory 对象

1. 调用三级缓存的 ObjectFactory.getObject()  返回的为一个 BeanProxy 对象
2. 如果当前对象被 AOP 进行切面代理，每次都将返回一个新的对象 （不符合单例）
3. 所以将产生的 BeanProxy 对象放入到二级缓存中，下次直接获取即可



### IoC 容器的启动流程

```java
public AnnotationConfigApplicationContext(Class<?>... componentClasses){
    // 1.加载 RootBeanDefinition 2.解析配置类 3.解析@Import和@Bean
    this();
    
    // 注册配置类
    register(componentClasses);
    
    // 下面的加载 bean 流程
    refresh();
}
```

### IoC 容器加载 bean 流程

1. prepareRefresh() **刷新预处理**
2. obitionBeanFactory() 销毁 old BeanFactory **创建新 BeanFacotry** 并注册到 BeanDefitionRegistry
3. prepareBeanFactory() **预处理**，加载 Context 的 ClassLoader
4. /
5. postProcessBeanFactory() **前置处理**
6. invokeBeanFactoryPostProcessors()  **实例化 BeanFactroyPostProcess** 的 bean
7. registerBeanPostProcessors() **注册 BeanPostProcess 的后置处理**
8. /
9. initMessageResource() **初始化国际功能**
10. initApplicationEventMulticaster() **注册事件派发器**
11. onRefresh() **容器刷新**
12. /
13. registerListeners() **注册监听**
14. finishBeanFactoryInitialization() **初始化所有非懒加载的单例 Bean**
15. finishRefresh() **Context 刷新**



### 事务的传播机制

1. REQUIRED	有事务则加入，没有则创建
2. SUPPORTS	有事务则加入，没有则非事务运行
3. MANDATORY	有事务则加入，没有抛异常
4. REQUIRES_NEW	有事务则挂起，用重新创建
5. NOT_SUPPORTED	有事务则挂起，用非事务运行
6. NEVER	有事务则抛异常，用非事务运行
7. NESTED	局部回滚

### 事务失效的场景

1. 使用非代理的方式运行
2. 方法非 public 
3. 数据库不支持



## MySQL

### 数据库事务的四特性 ACID

1. 原子性（Actomicity）：多个操作只有一个最终结果
2. 一致性（Consistent）：多个事务读取同一数据应该是一样的
3. 隔离性（Isolation）：多个事务之间不应该相互干扰
4. 持久性（Durable）：事务的结果应该被永久的保存

InnoDB： `回滚日志(undo)`保证原子性 `重做日志(redo)`保证一致性和持久性 `锁`保证隔离性



### 数据错误术语

1. 脏读：读取未提交的数据，后未提交的数据被回滚
2. 不可重复读：多次读取的结果不一致
3. 幻读：出现新的数据，数据条数不一致



### 事务的隔离级别

读未提交（Read Uncommitted）：允许读取未提交的事务数据  ——幻读、脏读、不可重复读

读已提交（Read Commit）：允许读取已提交的事务数据  ——幻读、不可重复读

可重复读（Repeatable Read）：多个事务读取同一数据是一致的  ——幻读

顺序读（Serializable）：所有事务依次读取

#### 默认等级（Repeatable Read）

解决幻读的方案：

1. 采用 Serializable 级别，所有事务按照顺序执行（效率低）
3. 采用 Gap Lock + Next-Key Lock 方案，对一个范围进行加锁
3. 采用 MVCC （Mulite-Version Concurrency Control）方案，指定版本就可以确定是否为最新的数据



### 锁级别

#### 表级锁：（Serializable ）

1. 意向锁（Intention Lock）：MyISAM 和 InnoDB 都支持
2. MDL 锁：对表结构做修改时的锁
3. AUTO-INC 锁：自增时的锁，插入后自动释放

**显式使用：（默认会自动加）**

1. LOCK TABLES xx READ （可选 LOCAL：可以在表尾插入）
2. LOCK TABLES xx WRITE
3. （解锁）UNLOCK TALBES

#### 行级锁：（RC 和 RR）

1. 记录锁（Record Lock）：对某一行的 **索引项** 进行加锁，有锁才能修改和删除
2. 间隙锁（Gap Lock）：对指定行的 **前后索引区间** 进行加锁，其他事务不能在锁的区间内插入数据
   1. 唯一索引：锁住多条记录 OR 不存在的记录 会产生间隙锁
   2. 普通索引：不管什么都会产生间隙锁
3. 临键锁（Next-Key Lock）：对 **某一行的索引项 和 前后索引区间** 都加锁（记录锁+间隙锁），可解决幻读问题

**显式使用：**

使用 select ... IN LOCK SHARD MODE（行级读锁）

使用 select ... FOR UPDATE（行级写锁）



### 锁类型

#### 读写锁

1. 共享锁（Shared Lock，S）：允许持有锁 **读取行** 的事务，也叫读锁
2. 排他锁（Exclusive Lock，X）：允许持有锁 **修改行** 的事务，也叫写锁

**注意：普通的 select 是不会加行锁的，而是使用 MVCC 实现一致性，是无锁的**

在表级和行级都有读写锁

表级：MySQL 定义 

行级：InnoDB 提供

#### 意向锁

在 InnoDB 中支持多粒度锁，允许 表级锁 & 行级锁 共存。**意向锁是一个表级锁**

因为行和表都有锁，那么需要考虑如何让这两种锁共存 ？就有了

参考：https://www.51cto.com/article/743293.html

1. 意向共享锁（Intention Shared Lock，IS）：有意向对 **某些行** 加共享锁（读），InnoDB 会自动先获取**表的意向读锁**
2. 意向排他锁（Intention Exclusive Lock，IX）：有意向对 **某项行** 加排他锁（写），InnoDB 会自动获取**表的意向写锁**

作用：

1. 当在使用行级锁时，引擎会自动添加表级意向锁（意向锁不互斥：多行锁可以同时）
2. 当其他事务在需要获取表级锁（互斥的情况）的时候，则只需要判定是否存在意向锁即可
3. **避免了互斥的情况下，需要去判定每行是否存在排他锁的问题**

互斥：

1. 意向锁之间都不互斥
2. 只有共享锁之间兼容，其他都互斥



### MVCC

InnoDB 在每行数据后面保存**系统的版本号**，**每开始一个新事务都会自动递增**，并作为事务的 ID（确保事务读取的行已存在，避免幻读）

InnoDB 中 MVCC 使用到的快照存储在 undo 日志中，该日志通过**回滚指针**把一个数据行的所有快照连接起来

版本链，在聚簇索引记录中的两个隐藏列：

1. trx_id：事务 id
2. roll_pointer：每次修改时都会把老版本写入到 undo 日志中，这个指针就指向这条聚簇索引的上一版本的位置



### 索引

#### 数据类型

1. HASH 索引：使用数据的 hash 值作为索引项，数据和索引项一对一（不能进行范围搜索，排序等）
2. B+ 树索引：非叶子节点存储索引，放入缓存提升效率；叶子节点存储数据，做双向链表进行范围查询

#### 索引类型

1. 聚簇（集）索引：保存索引 和 数据（不用再次查询）

   1. 主键索引 = 聚簇索引  = 覆盖索引，**一定会有主键索引，一定是聚簇索引。没有则使用其他唯一索引，没有则使用隐藏 id**

2. 非聚簇（集）索引：保存索引 和 主键值（通过主键值再次查询    --回表）

   1. 唯一索引 （UNIQUE）

   2. 联合索引：需要注意 **最左前缀匹配** 问题

      联合索引的索引键是以最左的字段来确定的，所以查询时未指定最左字段则无法使用索引

   3. 全文索引（FULLTEXT）



### 查询执行

1. 接收到 select 语句后，在 query cache 中匹配是否有相同的语句（大小写），有则直接返回

2. 将 select 语句交给解析器进行语法解析，生成解析树

3. 查询优化器生成执行计划，进行索引优化

4. 引擎执行 SQL 语句，得到查询结果。执行顺序：

   form > join > on > where > group by > avg,sum... > having >select > distinct >order by > limit

5. 开启 Query Cache 则放入，后返回结果



### 查询优化

1. explain 关键值： type（是否全表扫描）、rows（预估的行数）、 extra（详细的描述）

2. 语句优化：

   1. **查询条件使用索引**
   2. count 会全表扫描，预估可以使用 explain 方式
   3. 分页 start 值过大会缓慢，使用子查询 + 表连接解决
   4. 删除表会产生 undo 和 redo 日志，确定删除使用 trancate

3. 索引优化：

   1. 无法使用索引：><、!= 、IS NULL、OR、IN、NOT IN
   2. **使用短索引**
   3. 索引的区分度要高，唯一索引的重复率 < 0.1
   4. 定义外键的列一定要又索引
   5. 更新频繁的列不适合做索引
   6. 查询的数据较少可以通过联合索引来进行覆盖
   7. 联合索引要符合最左匹配原则

4. 设计优化：

   1. 表 < 200
   2. 列 < 40
   3. 行 < 500w
   4. 单表索引 < 5

5. 配置优化：

   **配置连接数**、禁用 Swap、增加内存、升级 SSD



### JOIN 查询

![](https://www.runoob.com/wp-content/uploads/2019/01/sql-join.png)

### 集群

#### 数据一致性问题

1. 异步复制：主库写入成功后直接返回，可能主从数据不一致
2. 半同步复制：等从库同步到 relay-log 后主库返回结果
3. 全同步复制：所有从库都执行成功后主库返回结果

#### 集群方案

1. **MySQL Replication**

   1. 从节点：开启 IO 线程，向主服务器请求同步 binlog 文件
   2. 主节点：开启 dump 线程，检查自己的 binlog 文件并发送给从节点
   3. 从节点：接受到 binlog 文件并保存到 Relay log 文件中
   4. 从节点：开启 SQL 线程，执行 Relay log 中的操作

   注：binlog 记录格式：STATEMENT | ROW | MIXED

2. MySQL Group Replication（MGR）：多个节点组成复制组，必须 n/2 + 1 的节点通过后才提交

3. **InnoDB Cluster**：高可用的解决方案

4. InnoDB CluseterSet：多个副本（不同区域）的 innodb cluster，提供容灾能力

5. InnoDB ReplicaSet：使用 MySQL Router 进行引导配置，非常适合扩展读取

6. Master-Master for MySQL（MMM）：支持双主的切换和管理的脚本，使用 prel 编写

7. **Master-High Avaliablity for MySQL（MHA）：**一款优秀的高可用环境下故障切换和主从提高的软件，可自动提升节点、切换主节点

8. Galera Cluster：多主集群，是一种高冗余架构

9. **MySQL Cluster：**支持 ACID 事务的实时数据库，基于分布式架构

#### MHA | QMHA 升级主节点步骤

1. 尝试修改 old-master 为 read_only = on，避免集群多点写入
2. 将 binlog server 保存 old-master 的 binlog 文件同步到  new-master 上
3. 在 new-master 使用 binlog 进行数据补齐，避免丢失数据



### 分库分表

将一个表拆分成多个（降低数据量压力），再将多个表放入到多个库（降低并发压力）分散压力

#### 分库和集群

​	集群：将一个数据库复制到多个机器（多个机器被视为一个库）

​	分库：将数据分布到多个机器（多个库）

#### ShardingSphere

1. 引入 `sharding-jdbc-spring-boot-starter` 包

2. 指定配置：

   ```yaml
   spring:
   	shardingsphere:
   		# 1.配置多个库信息
   		datasource:
   			names: d1, d2
   			d1:
   				type: com.zaxxr.hikari.HikariDataSource
   				driverClassName: com.mysql.cj.jdbc.Driver
   				jdbcUrl: jdbc:mysql://localhost:3306/sharding_db
   				username:
   				password:
   		# 2. 配置分片信息
   		sharding:
   			tables:
   				order:
   					# 2.1 分在那些库、表内
   					actual-data-nodes: d$->{1..2}.t_order_$->{1..2}
   					# 2.2 主键生成策略
   					key-generator:
   						cloumn: id
   						type: SNOWFLAKE | UUID
   					# 2.3 分库策略
   					database-strategy:
   						inline:
   							sharding-cloumn: id
   							algorithm-expression: d$->{id%2+1}
   					# 2.4 分表策略
   					table-strategy:
   						inline:
   							sharding-cloumn: id
   							algorithm-expression: t_order_$->{id%2+1}
   ```

#### 分片策略

1. inline：指定某一个行确定分片

2. strandard：

   1. precise-algorithm-class-name：新增时的自定义分片策略
   2. range-algorithm-class-name：查询范围时确定应该去哪些分片执行的策略

3. complex：多个分片键确定分片

4. hint：和 SQL 不相关的条件去分片（直接自行确定应该在那些库和表）

   例：下单人是成都的，那我就直接指定他去成都库查就行了

#### 读写分离方案

1. 配置主库： sharding.master-slave-rules.{库别名}.master-data-source-name: d1
2. 配置从库： sharding.master-slave-rules.{库别名}.slave-data-source-names[0]: d2
3. 指定逻辑库：sharding.tables.{表别名}.actual-data-nodes: ${库别名}.t_name
4. **在  MySQL 中设置读写库同步**



### 常见问题

#### 双写不中断迁移

1. 让新库加入到所有的读写操作中
2. 通过新库的起始 id 就可判断之前的是旧数据
3. 通过程序将旧库中的数据写入到新库中，写的时候判断 updateTime
4. 循环执行，直至新老一致，则可关闭旧库

#### 分布式自增唯一主键

1. 可用 redis 的方式 （10W级）
2. 雪花算法
3. 自定义主键生成策略

#### 富查询

多维度实时查询最常见的方式是：将查询的字段放到 ElasticSearch 中，那后续扩展加字段呢 ？

#### 深分页

1. 按游标进行查询 offset ?
2. 查询带上上一次查询排序后的最大 id（不能跳页）

#### 数据倾斜

分表 & 取余



## Redis

### 线程模型

服务器是一个事件驱动程序，服务器处理的事件分为：文件事件（主功能） 和 时间事件（处理AOF持久化等）

文件事件处理器的结构：

1. 多个 Socket
2. IO 多路复用程序
3. 文件事件分派器
4. 文件事件处理器

流程：

1. IO 多路复用程序监听多个 scoket 
2. 将产生事件的 Socket 放入队列中，一次获取一个交给事件分派器
3. 分派器将 Socket 给对应的事件处理器
4. 事件处理完后，才从队列中获取下一个 Socket

#### BIO - NIO - IO multiplexing

1. BIO（Blocking IO）：server 读取 client 发送的数据会阻塞，导致其他 client 无法连接（只能处理一个 client）
2. BIO + 线程池：读取 client 消息由其他线程执行，主线程就不会阻塞（耗费线程资源）
3. NIO（Nonblocking IO）：将 client 放入到一个数组中，隔一段事件遍历一次（无效遍历，线程态和内核态（read）切换）
4. IO multiplexing：将一批文件描述符通过系统调用给内核，让内核进行遍历，就不用切换了（应运而生 select poll epoll）

#### IO 多路复用

简单理解就是：一个服务端进程可以同时处理多个 Socket 描述符

- **多路**：多个客户端连接（连接就是 Socket 描述符）
- **复用**：使用单进程就能够实现同时处理多个客户端的连接

其发展可以分 **select -> poll -> epoll** 三个阶段来描述

redis IO 多路复用程序：

1. 通过包装常用的 select、poll、evport、kqueue 这些 IO 多路复用函数库来实现

2. 为每个 IO 多路复用函数库（ 各系统提供）都实现相同 API，所以底层实现是可以互换的

   **注：linux epoll 其他只有 select 函数**

#### Redis 6.0 多线程

参考：https://segmentfault.com/a/1190000041488709

将耗时的 Socket 读取、请求解析、写入等 IO 任务拆分给一组独立线程执行

让主线程只需要命令执行，高效处理多个连接请求（核心线程仍然是线程安全的）



### 数据类型 

参考链接：https://www.cnblogs.com/booksea/p/17729973.html | https://www.cnblogs.com/hunternet/p/12742390.html

| 数据类型      | 编码方式                               | 使用条件                |
| :------------ | :------------------------------------- | ----------------------- |
| String 字符串 | int、embstr、raw                       | 长度 < 44 = embstr      |
| List 列表     | ziplist、linkedlist、quicklist（3.2+） | <64byte <512 = ziplist  |
| Set 集合      | intset、hashtable                      | 整数 = intset           |
| ZSet 有序集合 | ziplist、skiplist                      | <64byte <128 =  ziplist |
| Hash 哈希表   | ziplist、hashtable                     | <64byte <512 = ziplist  |

#### 编码结构

**SDS 数组：**通过 len 和 free 记录字符数组的长度，优化 C 字符串

**ZipList：**类似数组在一片连续的内存存储数据，**允许存储数据的大小不同**（长度灵活，节约空间）

​	zlbytes 占用字节数，zltail 尾到头多少字节，zllen 节点数量(<65535)，zlend 末端标记

**QuickList：**= ZipList + LinkedList 将链表分段，每段使用 ZipList 来紧凑存储，多个用双向指针串联

​	因双向链表前后指针占用浪费，节点单独分配内存，加剧碎片化

**intSet：**可以存储 int16_t、int32_t、int64_t 整数，通过升级的方式节约内存（不可降级）

**SkipList：**在双向链表的基础上加多级索引，提高检索效率（数据量大）

**Dict：**又叫散列表（hash）键值对的结构

​	**整个数据库都是用此结构存储**  hash + 数组 + 链表（解决哈希碰撞）

​	当数据量大的时候，扩容（阈值 0.75）后重新计算 hash 值和移动数据到新数组中，会非常耗时

​	所以解决一次性扩容耗时过多的问题，引入渐进式 rehash ：

1. 创建新的 ht[1] 空间，让字典同时持有 ht[0] 和 h[1] 两个哈希表
2. 设置标记 rehashidx = 0 表示开始 rehash 操作
3. 新增在 ht[1] 上；修改、删除、查询在老 ht[0] 上
4. 在任何操作时，都会附带将 ht[0] 在 rehashidx 索引上的所有键值对移动到 ht[1] 上，然后 rehashidx 自增 1



### 持久化

1. RDB（redis database）默认的持久化策略（4.0+ 混合），按照**一定的时间将内存中的数据**以快照形式保存到硬盘中的 dump.rdb

   使用配置中的 save 定义时间段，因为是按照时间段保存，所以可能出现数据丢失

2. AOP（append only file）将**每次写命令**记录到单独的日志文件中（文件大，恢复慢，启动效率低）

   使用 appendfsync=always 表示每执行一个命令就写入文件，从而保证数据安全
   
   

### 事务

一次性、顺序性、排他性的执行一个队列中的一系列命令

实现方式：

1. MULTI：开启一个事务，总是返回OK。之后发送的指令会被放到队列中，直到  EXEC 被执行
2. EXEC：执行事务队列中的所有命令。按照先后顺序返回结果
3. WATCH：乐观锁，为事务提供 Check-And-Set（CAS）行为。监控一个或多个键，一旦被修改之后，其他指令不会执行；直到 EXEC
4. RECARD：客户端清空队列，并放弃执行事务
5. UNWATCH：取消 WATCH 对所有键的监控



### 内存淘汰策略

当内存不够时，全局的移除策略

1. noeviction：不移除，报错
2. allkeys-lru：移除最近最少使用的
3. allkeys-random：随机移除

设置了过期时间的键移除策略

1. volatile-lru：移除最近最少使用的
2. volatile-random：随机移除
3. volatile-ttl：移除快过期的



### 缓存失效策略

1. 定时清理：给设置了过期时间的 key 创建定时器
2. 惰性清理：在获取时判断（对内存不友好 --没有正常释放）
3. 定时扫描清理：在 100ms 内随机检查 20 个，若存在 25% 以上则循环删除



### 使用时读写策略

1. Cache Aside（旁路策略）：写数据后删除缓存，无缓存读数据库后写入到缓存

   缓存一致性：删除 -> 修改DB -> 等待再删除（双删）

2. Read / Write Through（读写穿透）：将 cache 作为主要存储，所有操作由组件写入数据库

3. Write Behind caching（异步缓存写入）：只更新 cache，批量异步更新 DB；例：多次写入影响效率，先放到缓存再一次写入

请求数据不一定在 cache 中：提前将热点数据写入到 cache



### 常见问题

**缓存雪崩：**同一时间多个缓存失效，导致请求都去查询数据库，短时间承受大量请求而崩掉

- Redis 高可用，主从 + 哨兵，Redis Cluster 
- 使用 hystrix 等限流 & 降级措施
- 设置不同的过期时间，避免同时失效
- 设置缓存标记，标记失效则更新数据缓存（那是不是还得配合锁 ？）

**缓存穿透：**缓存和数据库中都没此数据，数据库接受了大量无效请求而崩掉

- 加强参数校验，剔除无效参数
- 在缓存中新增无数据标记，并设置短一点的过期时间。防止同一 ID 暴力攻击
- 采用足够大的布隆过滤器

**缓存击穿：**数据库有数据，缓存中没有。并发访问数据库中的同一记录

- 热点数据永不过期，异步线程处理
- 查询后回写加互斥锁
- 缓存预热

**数据不一致：**缓存机器被打满，写入缓存失败；在 rehash 时网络波动多次 rehash，导致脏数据

- 进行重试，再不行加入到 mq 中，等待缓存机器恢复后删除，再次使用时从数据库加入缓存
- 缓存时间调短，早点更新新数据 ？
- 不使用 rehash 进行漂移，使用多层缓存 ？

**数据并发竞争：**大量用户同时查询同一缓存

- 回写加互斥锁，查询失败快速返回
- 保持缓存多备份，减少并发

**HotKey：**

- 对于可以预见的提前评估
- 使用工具（如 spark）找出最近历史的热点数据
- 将同一个 key 加个后缀，分成多份，分散压力
- 集群可以单节点进行主从复制 和 垂直扩容
- 使用应用内的缓存，注意设置上限

**BigKey：** String > 5mb | size > 5000

- 拆分成多个 key-value 的小 key
- 序列化后压缩存储的数据
- 定期清理失效数据



### 数据分区

1. hash % node_number：当出现节点加入或者退出，所有节点都将受到影响
2. hash + 顺时针（一致性hash）：计算 hash 后顺时针找到先遇见的节点存放，有节点变动只影响下一个节点
3. hash % 16383（redis cluster）：将所有的 key 分为 0-16383 个槽位，计算 hash 后取余



### 架构模式

#### 主从模式

通过读写分离，优化读和写不能同时进行的问题。但是主节点一旦挂掉，不能自动切换

所有的数据处理都在 master 上进行

主从复制原理：

1. salve 发送 psync 到 master
2. 如果是首次连接则全量复制， master 启动后台线程，生成 RDB 快照
3. master 发送 RDB，slave 先保存到硬盘，然后加载到内存
4. master 会将过程中的写命令保存到缓存，slave 实时同步
5. 如果断开连接，自动重连后会将增量数据发送到 slave

#### 哨兵模式

给主从模式配置哨兵，以实现自动的主从切换功能。提高系统可用性

适合读 > 写的情况，如果写多会对 master 形成同步压力

**主节点掉线后迁移机制**：

1. 确认主观掉线：Sentinel 会每秒一次向建立连接的节点发送 **PING** 命令，如果 **down-after-milliseconds** 内未回复则认为其掉线

2. 确认客观掉线：Sentinel 向其他监控此节点的哨兵查询主机状态，超过 **quornum** 数量的哨兵都认为其下线，则认为客观掉线

3. 选举 Leader Sentinel：在 Sentinel 中使用 Raft 算法选举出 Leader（Raft 状态： Follower | Candidate | Leader）

   1. 触发选举，所有节点初始化为 Follower 状态，term = 0

   2. 收到了其他节点的 RequestVote（投票） | AppendEnties（通知），则保持 Follower 状态

   3. 超时时间到但未收到消息，则自己开始竞选，修改为 Candidate 状态

      1. 创建一个 term（投票轮）
      2. **给自己投票**，并向其他节点发送 RequestVote 的消息

   4. **其他节点收到消息后会将票投给第一个收到 RequestVote 的节点**（也就是发起人）

   5. 在超时时间内，收到了大多数节点的同意，则转换为 Leader

   6. 向其他节点发送 AppendEnties 通知

      注：Raft 协议采用**每个节点随机超时时间**，先转为 Candidate 的节点会先发起投票，从而获得多数票

4. Leader Sentinel 确定升级节点：在 slave 中选择一个升级

   1. 去掉客观、主观掉线的节点
   2. 选择 slave-priority 最高的节点
   3. 选择数据偏移量大的节点（数据多）
   4. 选择 runid（pid）最小的节点（越小说明重启的少）

5. 故障转移：

   1. 让其他 slave 复制 new-master
   2. 客户端连接时返回 new-master 地址
   3. 新增 new-master 的 replicaof 配置； sentinel.conf 修改监控对象为 new-master

#### 集群模式

为避免单一节点负载过高导致不稳定，集群模式用**一致性哈希|哈希槽**将 key 分到各个节点上去

高可用：集群各个节点会探测相互是否存活，多个节点判定一个节点挂了，则将其踢出集群并选择一个从节点作为新主节点（哨兵类似）

避免了单点问题，但节点间同步会消耗部分性能

在写比较多的情况下使用此模式

### 心跳检测

slave 默认会以每秒一次的频率向 master 发送 ACK 命令

1. 检测连接状态，lag 值 = 0-1，超过则说明主从之间连接有故障

2. 通过配置防止 master 在不安全的情况下执行写命令

   min-slaves-to-write 3 ：表示在 slave < 3 时 master 不执行写入命令

   min-slaves-max-lag 10：表示在 lag > 10 时 master 不执行写入命令

3. 检测命令丢失，进行重试



### 分布式锁

#### WATCH 实现 Redis 乐观锁

WATCH 是 redis 自带的命令，可以监控一个或多个变量是否被更改，更改则其他指令不会执行

1. WATCH xxx
2. GET xxx 然后在 value += 1
3. EXEC，如果 value 被修改过则回滚

#### setnx 防止超卖

setnx 只有在当前 key 不存在时才会成功

加锁：jedis.set(key, value, "NX", "EX", expireTime)

释放锁：使用 redis + lua 

```java
String lua = "if redis.call('get', KEYS[1]) == ARGV[1] then"
    			+ " return redis.call('del', KEYS[1]) "
    		+ "else "
    			+"return 0 end";
Object result = jedis.eval(lua, Collections.singletonList(lockKey);
```

#### Redisson 分布式锁

在业务需要强一致性，不能重复获得锁的情况下可以使用。性能较低比较重量级



### Redis 优化

1. 使用短 key，KV 值太大可以拆分成几个小的
2. 尽量少用 keys *（这个命令是阻塞的）
3. 尽量设置过期时间，以保证会被清理
4. 如果不需要持久化的可以关闭以提升性能
5. 读写峰值单机 10W 左右，超过可使用 local-cache 配合，甚至多层 redis 缓存

### Redis 热升级

1. 创建一个 redis 壳程序，将 server 的所有属性保存为全局变量
2. 将 redis 的逻辑代码全部封装到动态链接库 so 中
3. 在后续升级时通过指令壳程序，重新加 redis-4.so 到 redis-5.so 文件 ，即可完成毫秒级升级



## Elastic Search

基础概略：https://www.cnblogs.com/jajian/p/11223992.html

### 基础概念

**倒排索引：**将数据拆分成词语，以词语为主题，记录其在那些 id 数据中存在，实现较快的搜索

**正排索引：**记录 id 数据中的所有词语，用以进行聚合、排序等操作。

1. doc_value 默认是开启的，不支持 text，存在磁盘中
2. field_data 需要在 _mapping 中自定义，使用堆外内存

**主分片：**number_of_shards 默认值：5 < v7.0 < 1 创建index后不可修改（分片数确定数据存储在哪个分片）是一个 Lucense 实例

**分片副本：**number_of_replicas 主分片的备份，实现高可用，减缓查询压力。创建后可以进行手动调整

**滚动索引：**调用接口设置其满足的条件则滚动，再用一个别名来访问多个索引



### 写过程和原理

#### 过程

1. 客户端发送请求数据到集群中的一个节点
2. 节点通过 hash(_routing) % shards_num 计算出在应该存储在哪个主分片
3. 将请求数据转发到主分片所在的节点上
4. 主分片写入成功后，将数据发送到副本上
5. 等待所有副本（可修改 index 配置：wait_for_active_shards=1）返回结果后，主分片节点将结果返回给终端请求的节点
6. 如果没达到 wait_for_active_shards 的数量 OR 超过 30s ，则返回错误

#### 原理

参考：https://cloud.tencent.com/developer/article/1531723

![es-write](D:\2-Work\4-Document\Life\Work\img\es-write.png)

1. 请求数据发送到主节点，解析数据后写入节点的 memory  buffer 中

2. 然后将 Id 和 doc 写入到 Translog 中进行备份

   设置 translog 写到磁盘的方式：

   1. index.translog.sync_intervel（默认 5s）将新增的 translog 写入到磁盘中
   2. index.translog.duriablity（request 每个请求| async 异步| fsync 文件刷新） 设置刷新到磁盘的方式

   **备注：**这个时候 geyById 的方式查询则可以直接使用  translog 中的数据（实时）

3. 节点在 buffer 超过阈值>1s（index.refresh_interval） >jvm 10% 则触发 **refresh** 操作，将缓存中的数据生成一个 Segment

4. Segment 是在 Filesystem Cache 中

   **备注：**因为 Segment 是不可变的，所以被放入内核中的文件系统缓存则会一直存在，除非文件系统缓存空间不足

5. 当 >30min || Translog > 512mb（index.translog.flush_threshold_size）则会触发 **flush** 操作

   1. 将当前 memory buffer 中的数据写入到 segment
   2. 调用 lucene 的 commit 方法将**所有的 segment fsync** 到硬盘，生成提交点
   3. 清空 translog 文件


##### Segment Merge

由上可知内存中的数据 1s 就会被写入到 Filesystem Cache 一个新的 Segment 中，那么就会产生很多小的 Segment 文件

遍历这些小的文件会影响效率，所以**占用不高时**会在后台执行一个定时进程合并小段到大段中去

1. 合并进程选择一部分大小相近的段，在后台将其合并到更大的段中
2. 合并结束后，old-segment 被删除，new-segment **被 flush 到磁盘**
3. 写入一个包含新段的提交点，new-segment 被打开可以搜索



### 更新 / 删除过程

#### 删除

1. 每个 Segement 中都维护了一个 **.del 文件**，删除时将文档 Id 状态更新为 deleted
2. 在查询时剔除掉 .del 中的文档，而不会物理删除
3. 当 **Segment merge** 的时候不会将 .del 中的文档进行合并到新的 Segment 中（变相删除）

#### 更新

Lucene 不支持部分更新，则 ElasticSearch 实现此功能：

1. 从 Segment 或 translog 中读取到同 ID 的文档，进行对比合并后更新 versionMap = v1
2. 加锁
3. 检查 versionMap 中的 version 是否和当前一致，不一致则重新准备更新
4. 将 version +=1 ，再将其加入到 Lucene 中，**先删除后新增**
5. 写入成功后将 versionMap = v2 
6. 释放锁



### 查询过程

#### GET 

直接通过 id 查询数据（实时的）

1. 先查询内存中的 translog 
2. 然后查询磁盘的 translog 
3. 然后再查询磁盘上的 Segment

#### Search 

查询分为两阶段：Query Then Fetch

**Query：**

1. 客户发送一个请求到节点（协调节点），节点创建一个 from + size  的队列
2. 这个节点会将请求转发给 **每个分片**（主分片 or 副本 随机轮询）
3. 每个分片执行查询并将其添加到本地的 from + size  的有序优先队列中（例：每个节点的 top10）
4. 每个分片返回各自队列中的 **ID 和 排序值** 给协调节点

**Fetch：**

1. 协调节点根据 ID 判定那些加入到**总结果的队列**中
2. 向相关分片提交多个 GET 请求
3. 每个分片加载出 ID 对应的数据返回给协调节点
4. 协调节点收集到相关数据后返回给客户端



### 集群配置

Zen Discovery 是内建的、默认的发现模块，提供**单播 和 基于文件**的发现

只需要配置文件中的 cluster.name（集群名称）和 discovery.zen.ping.unicast.hosts（单播的主机列表）即可自动组建集群

**主节点：**node.master = true

**数据节点：**node.data = true

一个节点既可以是主节点 也可以是数据节点

#### 选举主节点

主节点负责创建、删除索引、跟踪节点加入集群、追踪节点状态、分片分配等，**不负责文档级别的管理**

只有 node.master = true 的节点才有**选举权和被选举权**，其他节点不参与选举操作

参考：https://www.cnblogs.com/shanml/p/16684887.html|https://developer.aliyun.com/article/1082593

1. 节点启动后执行 PING 操作，当节点数超过 mininum_master_nodes 才开始选举，不够则重复 PING
2. 节点给自己所知道的备选节点中 ID 为最小的投票
3. 如果得票超过 discovery.zen.mininum_master_nodes && 自己也投票给自己，那么这个节点就是新的 master
4. 如果不满足则重复此过程

#### 脑裂问题

产生原因：

1. 网络抖动导致部分节点认为 master 掉线
2. master 节点负载过大，导致 es 进程失去响应
3. GC 较大内存导致失去响应

解决方案：

1. 延迟：提高 discovery.zen.ping_timeout 的值
2. 负载：设置 node.data = false 避免进行数据操作
3. 选举：设置 mininum_master_nodes = (主节点 / 2) + 1 超过半数才能选举 master



### 常见优化

#### 配置优化

1. 内存按照 50% 的比例分配给 jvm，并固定大小（ xmx = xms）
2. 剩余的 50% 留给文件系统缓存
3. 推荐 xmx 不超过 31gb （数值不固定）以确保虚拟机采用 zero-based 压缩指针算法来节约空间

#### 写优化

1. 初始化数据时设置 number_of_replicas = 0 ，避免副本建立索引
2. 使用自动生成 ID 
3. 合理的选择类型和分词器
4. 禁用搜索评分，延长索引刷新间隔

#### 读优化

1. 使用 filter 代替 query，减少评分环节
2. 使用滚动索引将数据集中

#### 深分页问题

1. 不允许跳页，采用 scroll 方式查询
2. 页面禁用深度跳页



## RabbitMQ

### 产品比较

|          | RabbitMQ            | Kafka             | RocketMQ            |
| -------- | ------------------- | ----------------- | ------------------- |
| 性能     | 1W+                 | **10W+**          | **10W+**            |
| 延迟     | **us**              | ms                | ms                  |
| 可用性   | 主从高可用          | 多副本分布式架构  | 分布式架构          |
| 可靠性   | **基本不丢**        | 配置优化后 0 丢失 | 配置优化后 0 丢失   |
| 支持语言 | **几乎所有**        | JAVA，PHP，Python | JAVA，C++（不成熟） |
|          |                     |                   |                     |
| 劣势     | erlang 不好二次开发 | 批量处理延迟较高  | 兼容不好            |

**为什么选择 RabbitMQ：**

1. 消息延迟低，适合业务场景
2. 支持语言多，方便进行集成开发

**为什么选择 Kafka：**

1. 强大的性能和吞吐量
2. 支持流式处理，是大数据处理、日志搜集等方面的标杆

**为什么选择 RocketMQ：**

1. 性能好吞吐量大、功能全面
2. 有活跃的中文社区



### 基础概念

![rabbitmq](D:\2-Work\4-Document\Life\Work\img\rabbitmq.png)

broker：一个消息队列服务器

v-host：虚拟主机（可以理解为 RabbitMQ 的多个实例）

exchange：交换机，用以接受消息

queue：队列，用以存储消息

routing-key：用以绑定 exchange 和 queue

connection：终端和服务器建立的连接

channel：在连接上创建的信道（一个连接多个信道）

#### Exchange 类型

参考：https://www.rabbitmq.com/getstarted.html 有 7 中类型，常用 5 种

1. 直接：投递给 **默认** 的交换机，一个消费
2. 工作：投递给 **默认** 的交换机，多个消费（轮询）
3. direct：绑定 routing-key 找到对应的队列
4. topic：支持 routeing-key 中携带匹配字符，找到相匹配的队列（*：一个字符 #：多个字符）
5. fanout：把消息复制同步到所有绑定的队列中
6. headers：匹配消息头（模式：all | any）

#### 生产流程

1. producer 连接服务器（broker）建立连接（connection）并在连接上创建一个信道（channel）
2. producer 配置 exchange 和 queue 然后将其使用 routing-key 关联起来
3. producer 发送消息到服务器
   1. 消息头中包含：routing-key \ priority（优先级）\ delivery-mode（存储模式）
4. 服务器根据 routing-key 找到对应的队列进行投递，没有则以 mandatory 属性进行退回（true） or 丢弃（false）

#### 消费流程

1. consumer 连接到服务器（broker）建立连接（connection）并在连接上创建一个信道（channel）
2. 向 broker 请求消费对应队列中的消息，设置响应的回调函数
3. 等待回应，接受返回消息
4. 返回 ack 确认消息
5. 服务器从队列中删除已经确认的消息

#### 死信队列

当消息成为 Dead Message 时，可以被重新发送到另一个交换机（DLX：dead letter exchange）

成为死信的条件：

1. 消息超时（TTL：Time to live，参数：x-message-ttl）
2. 消息被拒收 channel.basicRejected & requeue = false
3. 队列超过长度限制



###  集群搭建

1. 在多个虚拟机上安装 rabbitmq

2. 指定每个虚拟机的名称 /etc/hostname 

   命令：rabbitmqctl status 会显示： Status of node 'rabbit@node1'  ....

3. 复制 node1 的 cookie 到 node2,3（/var/lib/rabbitmq/.erlang.cookie）

   **注意：** 1. chmod 400 /var/lib/rabbitmq/.erlang.cookie    2. 用户组为：rabbit:rabbit

4. 修改每个节点的 /etc/hosts 文件

   192.168.100.10 node1 

5. 使用（rabbit-server -detached）启动三个独立的集群

6. 将节点加入到某个集群中去

   1. rabbitmqctl stop_app
   2. rabbitmqctl reset_app
   3. rabbitmqctl join_cluster rabbit@node1(status看到的) --ram（内存节点 default=disk）

#### 镜像集群

可以实现消息多节点存储，在 admin 中进行配置 policy 规则

1. pattern：匹配的正则表达式

2. ha-mode：镜像队列的模式

   all（所有节点） | exactly（指定数量） | nodes （指定节点）

3. ha-params：模式的值

4. ha-sync-mode：同步的方式

   automatic （自动）| manually（手动）

#### 集群代理

使用 HAProxy 进行代理配置即可



### 常见问题

**如何保证休息不丢失** ？

生产端：

1. 开启事务 txSelect() | txRollback() | txCommit()  
2. 设置为 channel.confirm 模式（失败发送 Nack 消息）

队列：**关键消息**开启持久化（deliveryMode = 2）

消费端：关闭自动确认（autoAck = false），进行手动确认（注意：1.忘记 ack 导致堆积 2.确认太慢导致堆积）

**如何让消息有序 ?** 

消息到队列中肯定是有序的，一个队列对应一个消费者即可

**如何让消息优先处理 ？**

设置消费优先级 x-max-priority（1-10）属性，数字大会被优先消费

**如何保证消息不被重复消费 ？**

幂等性：消息被执行多次 和 一次的影响相同

1. 添加版本号（不同则不执行）
2. 添加主键约束（后续执行会冲突并失败）
3. 记录关键 key 是否已经被处理

**如何处理消息堆积的情况 ？**

排查：堆积一定是生产和消费能力不匹配的问题导致的

1. 增加更多的消费者，提高消费速度
2. 使用新的队列接受消息，保证新消息的服务正常
3. 排查消费者能力不足的问题
4. 根据数据状态找回丢失的消息，进行重新投递

 

## RocketMQ

### 部署

#### 单机部署

下载安装包后运行 bin 目录下的 nameserver 和 broker 程序

#### 主从高集群

1. 各节点安装服务，开放防火墙等

2. 根据节点数量规划 nameserver 和 broker 及副本数量

3. 创建各个 broker 的配置文件

   ```properties
   brokerClusterName=cluster-name
   brokerName=order-broker
   # 0.master >0.slave
   brokerId=0
   nameserverAddr=10.11.1.10:9876;10.11.1.11:9876;
   ```

4. 使用 -c 指定配置文件启动 broker 和 nameserver

#### 监控

下载打包好的 rabbitmq-dashboard.jar 运行即可



### 常见模式

#### 基本模式

创建新消息：new Message("topic", "tags", "".getBytes())

同步发送：DefaultMQProducer.send(message)

异步发送：DefaultMQProducer.send(message, new SendCallback() { onSuccess(); onException(); })

单向发送（不管消息是否成功）：DefaultMQProducer.sendOneway(message)

消息拉取：DefaultPullConsumer.subscribe("topic")  consumer.poll()

在指定队列中拉取：

```java
// 获取 topic 的队列
Collection<MessageQueue> queues = consumer.fetchMessageQueues("topic");
// 分配队列
List<MessageQueue> listQueues = new ArrayList(queues);
consumer.assgin(listQueues);
// 从指定队列中拉取
consumer.seek(listQueues.get(0), offset);
```

消息推来：

```java
// 并发处理
DefaultMQPushConsumer.setMessageLister(new MessageListenerConcurrently() { 
	@Override
	public ConusmeConcurrentlyStatus consumeMessage(List<MessageExt> list, MessageListenerConcurrently context){ 
		// TODO 处理消息
        
        return ConsumerConcurrentlyStatus.
	} 
});

```

#### 顺序消息

是让指定的某一个队列中的消息是有序的，而不是让所有队列中的消息是有序的

生产：DefaultMQProducer.send(message, new MessageSelector() { // TODO 根据 ID 参数指定投递的队列 }, id)

消费：DefaultMQPushConsumer.setMessageLister(new MessageListenerOrderly(){ xxx })

#### 广播消息

**consumer**.setMessageModel(MessageModel.BROADCASTING（每个消费者都发） | CLUSETERING（选择一个消费者）)

#### 延迟消息

message.setDelayTimeLevel(1)   级别：1s 5s 10s 30s 1m 2m 3m 4m 5m 10m 20m 30m 1h 2h

message.setDelayTimeMs(1000L)

#### 过滤消息

tag：consumer.subscribe("topic", "tag_x || tag_y")

SQL：.subscribe("topic", MessageSelector.bySql("TAGS is not null and PROPS.key = value")) 

#### 事务消息

1. 实现事务回调实现方法：

   ```java
   public class TransactionListenerImpl implements TransactionListener{
       // 回调的事务执行方法
       @Override
       public LocalTransactionState executeLocalTransaction(Message message, Object o){
           
           return LocalTransactionState.COMMIT_MESSAGE | ROLLBACK_MESSAGE | UNKNOW;
       }
       
       // 回调的事务定时检测方法
       @Override
       public LocalTransactionState checkLocalTransaction(Message message, Object o){
           
           return LocalTransactionState.COMMIT_MESSAGE | ROLLBACK_MESSAGE | UNKNOW;
       }
   }
   ```

2. 绑定事务回调：producer.setTransactionListener(new TransactionListenerImpl())

3. 提交事务消息：producer.sendMessageInTransaction(message, args)



### 部分原理

#### 持久化原理

![rocketmq-file](D:\2-Work\4-Document\Life\Work\img\rocketmq-file.png)

CommitLog ：存放消息的文件，默认为 1G

IndexFile： 消息的索引文件，记录整个 broker 中的消息 key hash 和在 commitLog 中的偏移量。

1. IndexHead ：beginTimestamp \ endTimestamp \ beginPhyoffset \ endPhyoffset \ hashSlot count \ index count
2. hashslot（500w个） ：hash code
3. index（2000w个）：hashcode \ phyoffset \ timedif \ 

ConsumeQueue：定位消息的索引文件。记录 topic 和 queue 的消息具体存放的位置：commitLogOffset \ msgSize \ tagsCode

##### 存储优化

page cache：操作系统对文件的缓存，访问读取文件时会顺序的对其他相邻的数据文件进行预读取

顺序读写：ConsumeQueue 的文件小并且顺序读取的，接近内存性能

零拷贝：减少**用户态与内核态**的上下文切换和内存拷贝的次数、提升I/O的性能。常见实现是 mmap **在 Java 中 MappedByteBuffer**

#### 事务原理

![rocket-transcation](D:\2-Work\4-Document\Life\Work\img\rocket-transcation.png)

1. 服务器接收到消息，被标记为 ”暂不可投递“ 状态（半消息）
2. 确认半消息接受给生产者，生产执行本地的事务处理方法，并返回事务状态给服务器
3. 若当前状态为 UNKNOW ，则服务器定时回查消息（15次），生产者会返回当前状态
4. 根据回查状态处理消息

#### 延迟消息原理

临时存储 + 定时任务

1. 延时消息会被投递到 **SCHEDULE_TOPIC_XXX 临时主题**中，主题下有多个级别的延时队列
2. 然后启动一个定时任务检测投递时间
3. 将到达投递时间的消息进行投递

#### 负载均衡原理

生产者：设置 sendLatencyEnable 开关（根据上次请求的延时，延缓下次分配任务的时间）默认情况：轮询

消费者：

​	**前提：**push 消费模式也是封装 pull + 轮询 来实现的，所以两个模式都需要知道去哪个队列获取消息

​	**心跳发送：**

 1. Consumer 会将心跳发送到**所有 broker** 中
 2. 收到后会将它维护在 ConsumerManager 的本地缓存的 **consumerTable** 中
 3. 将封装后的通道消息保存在本地缓存的 **channelInfoTable** **中**

​	**负载均衡：**

​	Consumer 在启动时会启动 **RebalanceService** 的启动（20s），这个线程调用 RebalanceImpl.rebalanceByTopic() 实现负载均衡

1. 查询当前 topic 中的所有队列的集合（mqSet）

2. 查询当前 topic 的消费者列表

3. 用**队列平均分配算法**计算出消费者对应的队列是哪些

4. 更新当前的 processQueueTable

      过期的队列：标记为 Dropped = true，并获取（1s）队列锁后移除

      还在的队列：**判断是否过期 并 移除 push 模式的队列**

      新的队列：直接放入

5. 为每个 queue 创建一个 ProcessQueue 加入到 ProcessQueueTable 

6. 创建 pullRequest 放入到 **PullMessageService** 线程中的 pullRequestQueue 等待取出后发送请求



### 常见问题

#### 如何保证消息可用性 ？

生产者：

1. 投递消息的确认
2. 事务

消息中间件：持久化（同步刷盘 or 异步刷盘）

消费者：手动确认消息接受

#### 如何实现消息过滤 ？

1.TAG 2.bySql 3.Filter（自定义函数）

#### 如何处理消息积压 ？

queue > consumer：添加更多的消费者

queue <= consumer：消息迁移到其他 queue 



## Netty





## Docker



## Kubernates



## 排序算法

