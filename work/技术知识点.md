## 集合



## 多线程

### 线程状态

1. start \ run \ sleep（计时等待） \ wait （等待）\ yield（让行） \ join（等待其他执行）
2. sleep 和 wait 的区别
   1. wait 属于 object 类中的方法，需要获得对象的锁
   2. wait 需要在同步代码块中
   3. wait 会释放锁，sleep 不会
   4. sleep 延迟状态自动结束，wait 需要被唤醒

### 线程池

1. Fixed 、Single、Scheduled、Cache
2. 任务的顺序：coreSize > queueSize > maxSize 
3. 拒绝策略：直接拒绝、调用者运行、丢弃最老、直接丢弃
4. Fixed、Single 默认队列大小为 Integer.MAX ，可能 OOM
5. Scheduled、Cache 默认线程池大小为 Integer.MAX，可能 OOM
6. 线程池推荐大小：CPU密集 n+1 、IO密集 2n

### 线程安全

读多写少的情况下，推荐使用乐观锁（尽量减少加锁的行为）：Version \ Compara And Swap

#### synchronized

synchronized 修饰代码块（monitorenter monitorexit）和方法 （flags）

1. 实现：对象头中 Mark word 记录对象hash、锁信息（持有线程id 、锁状态等）、年龄分代、GC标志等
2. 锁状态：无锁、偏向锁（当前线程优先）、轻量锁（CAS避免切换线程）、重量锁（阻塞其他线程）

#### Lock

1. ReentrantLock 官方提供的互斥锁，锁实现采用自旋，不断循环调用CAS操作来避免线程进入内核阻塞状态
2. 公平锁的实现方式：所有的线程请求锁时，都将放入一个队列中。按照 FIFO 的方式获取锁
3. 公平锁因为要放入队列然后在获取，当只有一个线程时，也会执行此操作。涉及到切换，所以效率低

#### synchronized & ReentrantLock 

1. sync 是 JAVA 关键字，R 只是提供的一个 API
2. 原理：锁状态的升级，R 使用CAS自旋机制实现操作原子性 和 volatile 实现可见性
3. 使用：sync 自动释放，R 需要手动释放锁
4. sync 不可中断，R 可以使用超时方法、调用 interrupt 方法
5. sync 不可设置公平锁，R 可以设置

#### AQS 思想

抽象式的队列同步器，是一个用来构建锁和同步器的框架。

同步器：用以实现原子化操作的一种方案

队列：线程阻塞和唤醒时分配方案

常见实现：Lock 、CountDownLatch（计数）、Semaphore（信号量）

#### ThreadLocal

1. ThreadLocal 是指定的对象会被保存到 Thread.threadLocalMap 中
2. ThreadLocal 内存泄露的问题：Map 中 key 是对象的弱引用，可能被回收了。value 是强引用没有被回收

#### 锁优化

1. 如何优化锁的使用：
   1. 减少锁应用的范围
   2. 减小锁力度（拆分多个锁）
   3. 锁粗化（避免多次操作）例：在循环外加锁
   4. 根据场景选择不同的锁
   5. 使用 CAS 乐观锁 + volatile

#### 内存模型

1. 线程安全主要就是保护内存数据（资源）的一致性

   原子性 - sync

   可见性 - volatile \ final

   有序性

2. volatile 使用 lock 指令实现内存可见性 + 有序性，建立内存屏障并禁止指令重排
   1. 强制写入到主内存
   2. 写入会导致其他 core 缓存失效
   3. 禁止之后的指令重排到之后 lock 之前

## Spring

### 主要功能

1. IoC（Inverse of Controller）将对象的管理权限交给框架管理，IoC 容器实际上是 Map
2. DI（Dependancy Injection）使用容器将对象引入
3. AOP（Aspect-Oriented Programming）面向切面编程，降低系统模块耦合度

### Bean

#### 生命周期

singleton：和 IoC 容器一个周期

prototype：使用时创建，使用过程中一直存活，不用被 GC 回收

大致四个阶段：

1. 实例化（instantiation）
2. 属性赋值（populate）
3. 初始化（initialization）
4. 销毁（destruction）

#### 加载流程

1. 实例化（new Object）
2. 设置属性（设置各个属性值，注入依赖的 bean 等）
3. Aware（BeanNameAware、BeanFactoryAware、ApplicationContextAware）
4. BeanPostProcess 的 postProcessBeforeInitialization() 
5. 调用指定 init-method 方法
6. postProcessAfterInitialization()
7. 创建完成，可以使用

#### 清理 Bean

1. 实现的 DisposableBean 接口
2. 调用指定 destory-method 方法

#### 循环依赖

Spring 采用三级缓存的方式来解决循环依赖的问题

一级缓存（singletonObjects）：创建好的所有 singleton Bean

二级缓存（earlySingletonObjects）：在调用 getSingleton() 从三级缓存中移出的对象

三级缓存（singletonFactories）：刚实例化的 Bean **包装到 ObjectFactory 中**

![循环依赖的返回](img/spring三级缓存.png)

#### 为什么是三级缓存

一级：已设置完整属性的对象

三级：所有刚实例化的对象

为什么一三级要分开：区分不同属性状态的对象

二级：区分代理对象和 ObjectFactory 对象

1. 调用三级缓存的 ObjectFactory.getObject()  返回的为一个 BeanProxy 对象
2. 如果当前对象被 AOP 进行切面代理，每次都将返回一个新的对象 （不符合单例）
3. 所以将产生的 BeanProxy 对象放入到二级缓存中，下次直接获取即可

### IoC 容器的启动流程

```java
public AnnotationConfigApplicationContext(Class<?>... componentClasses){
    // 1.加载 RootBeanDefinition 2.解析配置类 3.解析@Import和@Bean
    this();
    
    // 注册配置类
    register(componentClasses);
    
    // 下面的加载 bean 流程
    refresh();
}
```

### IoC 容器加载 bean 流程

1. prepareRefresh() **刷新预处理**
2. obitionBeanFactory() 销毁 old BeanFactory **创建新 BeanFacotry** 并注册到 BeanDefitionRegistry
3. prepareBeanFactory() **预处理**，加载 Context 的 ClassLoader
4. /
5. postProcessBeanFactory() **前置处理**
6. invokeBeanFactoryPostProcessors()  **实例化 BeanFactroyPostProcess** 的 bean
7. registerBeanPostProcessors() **注册 BeanPostProcess 的后置处理**
8. /
9. initMessageResource() **初始化国际功能**
10. initApplicationEventMulticaster() **注册事件派发器**
11. onRefresh() **容器刷新**
12. /
13. registerListeners() **注册监听**
14. finishBeanFactoryInitialization() **初始化所有非懒加载的单例 Bean**
15. finishRefresh() **Context 刷新**

### 事务的传播机制

1. REQUIRED	有事务则加入，没有则创建
2. SUPPORTS	有事务则加入，没有则非事务运行
3. MANDATORY	有事务则加入，没有抛异常
4. REQUIRES_NEW	有事务则挂起，用重新创建
5. NOT_SUPPORTED	有事务则挂起，用非事务运行
6. NEVER	有事务则抛异常，用非事务运行
7. NESTED	局部回滚

### 事务失效的场景

1. 使用非代理的方式运行
2. 方法非 public 
3. 数据库不支持



## MySQL

### 数据库事务的四特性 ACID

1. 原子性（Actomicity）：多个操作只有一个最终结果
2. 一致性（Consistent）：多个事务读取同一数据应该是一样的
3. 隔离性（Isolation）：多个事务之间不应该相互干扰
4. 持久性（Durable）：事务的结果应该被永久的保存

InnoDB： `回滚日志(undo)`保证原子性 `重做日志(redo)`保证一致性和持久性 `锁`保证隔离性



### 数据错误术语

1. 脏读：读取未提交的数据，后未提交的数据被回滚
2. 不可重复读：多次读取的结果不一致
3. 幻读：出现新的数据，数据条数不一致



### 事务的隔离级别

读未提交（Read Uncommitted）：允许读取未提交的事务数据  ——幻读、脏读、不可重复读

读已提交（Read Commit）：允许读取已提交的事务数据  ——幻读、不可重复读

可重复读（Repeatable Read）：多个事务读取同一数据是一致的  ——幻读

顺序读（Serializable）：所有事务依次读取

#### 默认等级（Repeatable Read）

解决幻读的方案：

1. 采用 Serializable 级别，所有事务按照顺序执行（效率低）
3. 采用 Gap Lock + Next-Key Lock 方案，对一个范围进行加锁
3. 采用 MVCC （Mulite-Version Concurrency Control）方案，指定版本就可以确定是否为最新的数据



### 锁级别

#### 表级锁：（Serializable ）

1. 意向锁（Intention Lock）：MyISAM 和 InnoDB 都支持
2. MDL 锁：对表结构做修改时的锁
3. AUTO-INC 锁：自增时的锁，插入后自动释放

**显式使用：（默认会自动加）**

1. LOCK TABLES xx READ （可选 LOCAL：可以在表尾插入）
2. LOCK TABLES xx WRITE
3. （解锁）UNLOCK TALBES

#### 行级锁：（RC 和 RR）

1. 记录锁（Record Lock）：对某一行的 **索引项** 进行加锁，有锁才能修改和删除
2. 间隙锁（Gap Lock）：对指定行的 **前后索引区间** 进行加锁，其他事务不能在锁的区间内插入数据
   1. 唯一索引：锁住多条记录 OR 不存在的记录 会产生间隙锁
   2. 普通索引：不管什么都会产生间隙锁
3. 临键锁（Next-Key Lock）：对 **某一行的索引项 和 前后索引区间** 都加锁（记录锁+间隙锁），可解决幻读问题

**显式使用：**

使用 select ... IN LOCK SHARD MODE（行级读锁）

使用 select ... FOR UPDATE（行级写锁）



### 锁类型

#### 读写锁

1. 共享锁（Shared Lock，S）：允许持有锁 **读取行** 的事务，也叫读锁
2. 排他锁（Exclusive Lock，X）：允许持有锁 **修改行** 的事务，也叫写锁

**注意：普通的 select 是不会加行锁的，而是使用 MVCC 实现一致性，是无锁的**

在表级和行级都有读写锁

表级：MySQL 定义 

行级：InnoDB 提供

#### 意向锁

在 InnoDB 中支持多粒度锁，允许 表级锁 & 行级锁 共存。**意向锁是一个表级锁**

因为行和表都有锁，那么需要考虑如何让这两种锁共存 ？就有了

参考：https://www.51cto.com/article/743293.html

1. 意向共享锁（Intention Shared Lock，IS）：有意向对 **某些行** 加共享锁（读），InnoDB 会自动先获取**表的意向读锁**
2. 意向排他锁（Intention Exclusive Lock，IX）：有意向对 **某项行** 加排他锁（写），InnoDB 会自动获取**表的意向写锁**

作用：

1. 当在使用行级锁时，引擎会自动添加表级意向锁（意向锁不互斥：多行锁可以同时）
2. 当其他事务在需要获取表级锁（互斥的情况）的时候，则只需要判定是否存在意向锁即可
3. **避免了互斥的情况下，需要去判定每行是否存在排他锁的问题**

互斥：

1. 意向锁之间都不互斥
2. 只有共享锁之间兼容，其他都互斥



### MVCC

InnoDB 在每行数据后面保存**系统的版本号**，**每开始一个新事务都会自动递增**，并作为事务的 ID（确保事务读取的行已存在，避免幻读）

InnoDB 中 MVCC 使用到的快照存储在 undo 日志中，该日志通过**回滚指针**把一个数据行的所有快照连接起来

版本链，在聚簇索引记录中的两个隐藏列：

1. trx_id：事务 id
2. roll_pointer：每次修改时都会把老版本写入到 undo 日志中，这个指针就指向这条聚簇索引的上一版本的位置



### 索引

#### 数据类型

1. HASH 索引：使用数据的 hash 值作为索引项，数据和索引项一对一（不能进行范围搜索，排序等）
2. B+ 树索引：非叶子节点存储索引，放入缓存提升效率；叶子节点存储数据，做双向链表进行范围查询

#### 索引类型

1. 聚簇（集）索引：保存索引 和 数据（不用再次查询）

   1. 主键索引 = 聚簇索引  = 覆盖索引，**一定会有主键索引，一定是聚簇索引。没有则使用其他唯一索引，没有则使用隐藏 id**

2. 非聚簇（集）索引：保存索引 和 主键值（通过主键值再次查询    --回表）

   1. 唯一索引 （UNIQUE）

   2. 联合索引：需要注意 **最左前缀匹配** 问题

      联合索引的索引键是以最左的字段来确定的，所以查询时未指定最左字段则无法使用索引

   3. 全文索引（FULLTEXT）



### 查询执行

1. 接收到 select 语句后，在 query cache 中匹配是否有相同的语句（大小写），有则直接返回

2. 将 select 语句交给解析器进行语法解析，生成解析树

3. 查询优化器生成执行计划，进行索引优化

4. 引擎执行 SQL 语句，得到查询结果。执行顺序：

   form > join > on > where > group by > avg,sum... > having >select > distinct >order by > limit

5. 开启 Query Cache 则放入，后返回结果



### 查询优化

1. explain 关键值： type（是否全表扫描）、rows（预估的行数）、 extra（详细的描述）

2. 语句优化：

   1. **查询条件使用索引**
   2. count 会全表扫描，预估可以使用 explain 方式
   3. 分页 start 值过大会缓慢，使用子查询 + 表连接解决
   4. 删除表会产生 undo 和 redo 日志，确定删除使用 trancate

3. 索引优化：

   1. 无法使用索引：><、!= 、IS NULL、OR、IN、NOT IN
   2. **使用短索引**
   3. 索引的区分度要高，唯一索引的重复率 < 0.1
   4. 定义外键的列一定要又索引
   5. 更新频繁的列不适合做索引
   6. 查询的数据较少可以通过联合索引来进行覆盖
   7. 联合索引要符合最左匹配原则

4. 设计优化：

   1. 表 < 200
   2. 列 < 40
   3. 行 < 500w
   4. 单表索引 < 5

5. 配置优化：

   **配置连接数**、禁用 Swap、增加内存、升级 SSD



### JOIN 查询

![](https://www.runoob.com/wp-content/uploads/2019/01/sql-join.png)

### 集群

#### 数据一致性问题

1. 异步复制：主库写入成功后直接返回，可能主从数据不一致
2. 半同步复制：等从库同步到 relay-log 后主库返回结果
3. 全同步复制：所有从库都执行成功后主库返回结果

#### 集群方案

1. **MySQL Replication**

   1. 从节点：开启 IO 线程，向主服务器请求同步 binlog 文件
   2. 主节点：开启 dump 线程，检查自己的 binlog 文件并发送给从节点
   3. 从节点：接受到 binlog 文件并保存到 Relay log 文件中
   4. 从节点：开启 SQL 线程，执行 Relay log 中的操作

   注：binlog 记录格式：STATEMENT | ROW | MIXED

2. MySQL Group Replication（MGR）：多个节点组成复制组，必须 n/2 + 1 的节点通过后才提交

3. **InnoDB Cluster**：高可用的解决方案

4. InnoDB CluseterSet：多个副本（不同区域）的 innodb cluster，提供容灾能力

5. InnoDB ReplicaSet：使用 MySQL Router 进行引导配置，非常适合扩展读取

6. Master-Master for MySQL（MMM）：支持双主的切换和管理的脚本，使用 prel 编写

7. **Master-High Avaliablity for MySQL（MHA）：**一款优秀的高可用环境下故障切换和主从提高的软件，可自动提升节点、切换主节点

8. Galera Cluster：多主集群，是一种高冗余架构

9. **MySQL Cluster：**支持 ACID 事务的实时数据库，基于分布式架构

#### MHA | QMHA 升级主节点步骤

1. 尝试修改 old-master 为 read_only = on，避免集群多点写入
2. 将 binlog server 保存 old-master 的 binlog 文件同步到  new-master 上
3. 在 new-master 使用 binlog 进行数据补齐，避免丢失数据



### 分库分表

将一个表拆分成多个（降低数据量压力），再将多个表放入到多个库（降低并发压力）分散压力

#### 分库和集群

​	集群：将一个数据库复制到多个机器（多个机器被视为一个库）

​	分库：将数据分布到多个机器（多个库）

#### ShardingSphere

1. 引入 `sharding-jdbc-spring-boot-starter` 包

2. 指定配置：

   ```yaml
   spring:
   	shardingsphere:
   		# 1.配置多个库信息
   		datasource:
   			names: d1, d2
   			d1:
   				type: com.zaxxr.hikari.HikariDataSource
   				driverClassName: com.mysql.cj.jdbc.Driver
   				jdbcUrl: jdbc:mysql://localhost:3306/sharding_db
   				username:
   				password:
   		# 2. 配置分片信息
   		sharding:
   			tables:
   				order:
   					# 2.1 分在那些库、表内
   					actual-data-nodes: d$->{1..2}.t_order_$->{1..2}
   					# 2.2 主键生成策略
   					key-generator:
   						cloumn: id
   						type: SNOWFLAKE | UUID
   					# 2.3 分库策略
   					database-strategy:
   						inline:
   							sharding-cloumn: id
   							algorithm-expression: d$->{id%2+1}
   					# 2.4 分表策略
   					table-strategy:
   						inline:
   							sharding-cloumn: id
   							algorithm-expression: t_order_$->{id%2+1}
   ```

#### 分片策略

1. inline：指定某一个行确定分片

2. strandard：

   1. precise-algorithm-class-name：新增时的自定义分片策略
   2. range-algorithm-class-name：查询范围时确定应该去哪些分片执行的策略

3. complex：多个分片键确定分片

4. hint：和 SQL 不相关的条件去分片（直接自行确定应该在那些库和表）

   例：下单人是成都的，那我就直接指定他去成都库查就行了

#### 读写分离方案

1. 配置主库： sharding.master-slave-rules.{库别名}.master-data-source-name: d1
2. 配置从库： sharding.master-slave-rules.{库别名}.slave-data-source-names[0]: d2
3. 指定逻辑库：sharding.tables.{表别名}.actual-data-nodes: ${库别名}.t_name
4. **在  MySQL 中设置读写库同步**



### 常见问题

#### 双写不中断迁移

1. 让新库加入到所有的读写操作中
2. 通过新库的起始 id 就可判断之前的是旧数据
3. 通过程序将旧库中的数据写入到新库中，写的时候判断 updateTime
4. 循环执行，直至新老一致，则可关闭旧库

#### 分布式自增唯一主键

1. 可用 redis 的方式 （10W级）
2. 雪花算法
3. 自定义主键生成策略

#### 富查询

多维度实时查询最常见的方式是：将查询的字段放到 ElasticSearch 中，那后续扩展加字段呢 ？

#### 深分页

1. 按游标进行查询 offset ?
2. 查询带上上一次查询排序后的最大 id（不能跳页）

#### 数据倾斜

分表 & 取余



## Redis

### 线程模型

服务器是一个事件驱动程序，服务器处理的事件分为：文件事件（主功能） 和 时间事件（处理AOF持久化等）

文件事件处理器的结构：

1. 多个 Socket
2. IO 多路复用程序
3. 文件事件分派器
4. 文件事件处理器

流程：

1. IO 多路复用程序监听多个 scoket 
2. 将产生事件的 Socket 放入队列中，一次获取一个交给事件分派器
3. 分派器将 Socket 给对应的事件处理器
4. 事件处理完后，才从队列中获取下一个 Socket

#### BIO - NIO - IO multiplexing

1. BIO（Blocking IO）：server 读取 client 发送的数据会阻塞，导致其他 client 无法连接（只能处理一个 client）
2. BIO + 线程池：读取 client 消息由其他线程执行，主线程就不会阻塞（耗费线程资源）
3. NIO（Nonblocking IO）：将 client 放入到一个数组中，隔一段事件遍历一次（无效遍历，线程态和内核态（read）切换）
4. IO multiplexing：将一批文件描述符通过系统调用给内核，让内核进行遍历，就不用切换了（应运而生 select poll epoll）

#### IO 多路复用

简单理解就是：一个服务端进程可以同时处理多个 Socket 描述符

- **多路**：多个客户端连接（连接就是 Socket 描述符）
- **复用**：使用单进程就能够实现同时处理多个客户端的连接

其发展可以分 **select -> poll -> epoll** 三个阶段来描述

redis IO 多路复用程序：

1. 通过包装常用的 select、poll、evport、kqueue 这些 IO 多路复用函数库来实现

2. 为每个 IO 多路复用函数库（ 各系统提供）都实现相同 API，所以底层实现是可以互换的

   **注：linux epoll 其他只有 select 函数**

#### Redis 6.0 多线程

参考：https://segmentfault.com/a/1190000041488709

将耗时的 Socket 读取、请求解析、写入等 IO 任务拆分给一组独立线程执行

让主线程只需要命令执行，高效处理多个连接请求（核心线程仍然是线程安全的）



### 数据类型 

参考链接：https://www.cnblogs.com/booksea/p/17729973.html | https://www.cnblogs.com/hunternet/p/12742390.html

| 数据类型      | 编码方式                               | 使用条件                |
| :------------ | :------------------------------------- | ----------------------- |
| String 字符串 | int、embstr、raw                       | 长度 < 44 = embstr      |
| List 列表     | ziplist、linkedlist、quicklist（3.2+） | <64byte <512 = ziplist  |
| Set 集合      | intset、hashtable                      | 整数 = intset           |
| ZSet 有序集合 | ziplist、skiplist                      | <64byte <128 =  ziplist |
| Hash 哈希表   | ziplist、hashtable                     | <64byte <512 = ziplist  |

#### 编码结构

**SDS 数组：**通过 len 和 free 记录字符数组的长度，优化 C 字符串

**ZipList：**类似数组在一片连续的内存存储数据，**允许存储数据的大小不同**（长度灵活，节约空间）

​	zlbytes 占用字节数，zltail 尾到头多少字节，zllen 节点数量(<65535)，zlend 末端标记

**QuickList：**= ZipList + LinkedList 将链表分段，每段使用 ZipList 来紧凑存储，多个用双向指针串联

​	因双向链表前后指针占用浪费，节点单独分配内存，加剧碎片化

**intSet：**可以存储 int16_t、int32_t、int64_t 整数，通过升级的方式节约内存（不可降级）

**SkipList：**在双向链表的基础上加多级索引，提高检索效率（数据量大）

**Dict：**又叫散列表（hash）键值对的结构

​	**整个数据库都是用此结构存储**  hash + 数组 + 链表（解决哈希碰撞）

​	当数据量大的时候，扩容（阈值 0.75）后重新计算 hash 值和移动数据到新数组中，会非常耗时

​	所以解决一次性扩容耗时过多的问题，引入渐进式 rehash ：

1. 创建新的 ht[1] 空间，让字典同时持有 ht[0] 和 h[1] 两个哈希表
2. 设置标记 rehashidx = 0 表示开始 rehash 操作
3. 新增在 ht[1] 上；修改、删除、查询在老 ht[0] 上
4. 在任何操作时，都会附带将 ht[0] 在 rehashidx 索引上的所有键值对移动到 ht[1] 上，然后 rehashidx 自增 1



### 持久化

1. RDB（redis database）默认的持久化策略（4.0+ 混合），按照**一定的时间将内存中的数据**以快照形式保存到硬盘中的 dump.rdb

   使用配置中的 save 定义时间段，因为是按照时间段保存，所以可能出现数据丢失

2. AOP（append only file）将**每次写命令**记录到单独的日志文件中（文件大，恢复慢，启动效率低）

   使用 appendfsync=always 表示每执行一个命令就写入文件，从而保证数据安全
   
   

### 事务

一次性、顺序性、排他性的执行一个队列中的一系列命令

实现方式：

1. MULTI：开启一个事务，总是返回OK。之后发送的指令会被放到队列中，直到  EXEC 被执行
2. EXEC：执行事务队列中的所有命令。按照先后顺序返回结果
3. WATCH：乐观锁，为事务提供 Check-And-Set（CAS）行为。监控一个或多个键，一旦被修改之后，其他指令不会执行；直到 EXEC
4. RECARD：客户端清空队列，并放弃执行事务
5. UNWATCH：取消 WATCH 对所有键的监控



### 内存淘汰策略

当内存不够时，全局的移除策略

1. noeviction：不移除，报错
2. allkeys-lru：移除最近最少使用的
3. allkeys-random：随机移除

设置了过期时间的键移除策略

1. volatile-lru：移除最近最少使用的
2. volatile-random：随机移除
3. volatile-ttl：移除快过期的



### 缓存失效策略

1. 定时清理：给设置了过期时间的 key 创建定时器
2. 惰性清理：在获取时判断（对内存不友好 --没有正常释放）
3. 定时扫描清理：在 100ms 内随机检查 20 个，若存在 25% 以上则循环删除



### 使用时读写策略

1. Cache Aside（旁路策略）：写数据后删除缓存，无缓存读数据库后写入到缓存

   缓存一致性：删除 -> 修改DB -> 等待再删除（双删）

2. Read / Write Through（读写穿透）：将 cache 作为主要存储，所有操作由组件写入数据库

3. Write Behind caching（异步缓存写入）：只更新 cache，批量异步更新 DB；例：多次写入影响效率，先放到缓存再一次写入

请求数据不一定在 cache 中：提前将热点数据写入到 cache



### 常见问题

**缓存雪崩：**同一时间多个缓存失效，导致请求都去查询数据库，短时间承受大量请求而崩掉

- Redis 高可用，主从 + 哨兵，Redis Cluster 
- 使用 hystrix 等限流 & 降级措施
- 设置不同的过期时间，避免同时失效
- 设置缓存标记，标记失效则更新数据缓存（那是不是还得配合锁 ？）

**缓存穿透：**缓存和数据库中都没此数据，数据库接受了大量无效请求而崩掉

- 加强参数校验，剔除无效参数
- 在缓存中新增无数据标记，并设置短一点的过期时间。防止同一 ID 暴力攻击
- 采用足够大的布隆过滤器

**缓存击穿：**数据库有数据，缓存中没有。并发访问数据库中的同一记录

- 热点数据永不过期，异步线程处理
- 查询后回写加互斥锁
- 缓存预热

**数据不一致：**缓存机器被打满，写入缓存失败；在 rehash 时网络波动多次 rehash，导致脏数据

- 进行重试，再不行加入到 mq 中，等待缓存机器恢复后删除，再次使用时从数据库加入缓存
- 缓存时间调短，早点更新新数据 ？
- 不使用 rehash 进行漂移，使用多层缓存 ？

**数据并发竞争：**大量用户同时查询同一缓存

- 回写加互斥锁，查询失败快速返回
- 保持缓存多备份，减少并发

**HotKey：**

- 对于可以预见的提前评估
- 使用工具（如 spark）找出最近历史的热点数据
- 将同一个 key 加个后缀，分成多份，分散压力
- 集群可以单节点进行主从复制 和 垂直扩容
- 使用应用内的缓存，注意设置上限

**BigKey：** String > 5mb | size > 5000

- 拆分成多个 key-value 的小 key
- 序列化后压缩存储的数据
- 定期清理失效数据



### 数据分区

1. hash % node_number：当出现节点加入或者退出，所有节点都将受到影响
2. hash + 顺时针（一致性hash）：计算 hash 后顺时针找到先遇见的节点存放，有节点变动只影响下一个节点
3. hash % 16383（redis cluster）：将所有的 key 分为 0-16383 个槽位，计算 hash 后取余



### 架构模式

#### 主从模式

通过读写分离，优化读和写不能同时进行的问题。但是主节点一旦挂掉，不能自动切换

所有的数据处理都在 master 上进行

主从复制原理：

1. salve 发送 psync 到 master
2. 如果是首次连接则全量复制， master 启动后台线程，生成 RDB 快照
3. master 发送 RDB，slave 先保存到硬盘，然后加载到内存
4. master 会将过程中的写命令保存到缓存，slave 实时同步
5. 如果断开连接，自动重连后会将增量数据发送到 slave

#### 哨兵模式

给主从模式配置哨兵，以实现自动的主从切换功能。提高系统可用性

适合读 > 写的情况，如果写多会对 master 形成同步压力

**主节点掉线后迁移机制**：

1. 确认主观掉线：Sentinel 会每秒一次向建立连接的节点发送 **PING** 命令，如果 **down-after-milliseconds** 内未回复则认为其掉线

2. 确认客观掉线：Sentinel 向其他监控此节点的哨兵查询主机状态，超过 **quornum** 数量的哨兵都认为其下线，则认为客观掉线

3. 选举 Leader Sentinel：在 Sentinel 中使用 Raft 算法选举出 Leader（Raft 状态： Follower | Candidate | Leader）

   1. 触发选举，所有节点初始化为 Follower 状态，term = 0

   2. 收到了其他节点的 RequestVote（投票） | AppendEnties（通知），则保持 Follower 状态

   3. 超时时间到但未收到消息，则自己开始竞选，修改为 Candidate 状态

      1. 创建一个 term（投票轮）
      2. **给自己投票**，并向其他节点发送 RequestVote 的消息

   4. **其他节点收到消息后会将票投给第一个收到 RequestVote 的节点**（也就是发起人）

   5. 在超时时间内，收到了大多数节点的同意，则转换为 Leader

   6. 向其他节点发送 AppendEnties 通知

      注：Raft 协议采用**每个节点随机超时时间**，先转为 Candidate 的节点会先发起投票，从而获得多数票

4. Leader Sentinel 确定升级节点：在 slave 中选择一个升级

   1. 去掉客观、主观掉线的节点
   2. 选择 slave-priority 最高的节点
   3. 选择数据偏移量大的节点（数据多）
   4. 选择 runid（pid）最小的节点（越小说明重启的少）

5. 故障转移：

   1. 让其他 slave 复制 new-master
   2. 客户端连接时返回 new-master 地址
   3. 新增 new-master 的 replicaof 配置； sentinel.conf 修改监控对象为 new-master

#### 集群模式

为避免单一节点负载过高导致不稳定，集群模式用**一致性哈希|哈希槽**将 key 分到各个节点上去

高可用：集群各个节点会探测相互是否存活，多个节点判定一个节点挂了，则将其踢出集群并选择一个从节点作为新主节点（哨兵类似）

避免了单点问题，但节点间同步会消耗部分性能

在写比较多的情况下使用此模式

### 心跳检测

slave 默认会以每秒一次的频率向 master 发送 ACK 命令

1. 检测连接状态，lag 值 = 0-1，超过则说明主从之间连接有故障

2. 通过配置防止 master 在不安全的情况下执行写命令

   min-slaves-to-write 3 ：表示在 slave < 3 时 master 不执行写入命令

   min-slaves-max-lag 10：表示在 lag > 10 时 master 不执行写入命令

3. 检测命令丢失，进行重试



### 分布式锁

#### WATCH 实现 Redis 乐观锁

WATCH 是 redis 自带的命令，可以监控一个或多个变量是否被更改，更改则其他指令不会执行

1. WATCH xxx
2. GET xxx 然后在 value += 1
3. EXEC，如果 value 被修改过则回滚

#### setnx 防止超卖

setnx 只有在当前 key 不存在时才会成功

加锁：jedis.set(key, value, "NX", "EX", expireTime)

释放锁：使用 redis + lua 

```java
String lua = "if redis.call('get', KEYS[1]) == ARGV[1] then"
    			+ " return redis.call('del', KEYS[1]) "
    		+ "else "
    			+"return 0 end";
Object result = jedis.eval(lua, Collections.singletonList(lockKey);
```

#### Redisson 分布式锁

在业务需要强一致性，不能重复获得锁的情况下可以使用。性能较低比较重量级



### Redis 优化

1. 使用短 key，KV 值太大可以拆分成几个小的
2. 尽量少用 keys *（这个命令是阻塞的）
3. 尽量设置过期时间，以保证会被清理
4. 如果不需要持久化的可以关闭以提升性能
5. 读写峰值单机 10W 左右，超过可使用 local-cache 配合，甚至多层 redis 缓存

### Redis 热升级

1. 创建一个 redis 壳程序，将 server 的所有属性保存为全局变量
2. 将 redis 的逻辑代码全部封装到动态链接库 so 中
3. 在后续升级时通过指令壳程序，重新加 redis-4.so 到 redis-5.so 文件 ，即可完成毫秒级升级



## Elastic Search



## RabbitMQ



## Netty



## Docker



## Kubernates



## 排序算法

